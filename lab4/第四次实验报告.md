<h1 align="center"> lab4：进程管理 </h1>

张德民 刘越帅 欧广元

## 实验目的

- 了解虚拟内存管理的基本结构，掌握虚拟内存的组织与管理方式
- 了解内核线程创建/执行的管理过程
- 了解内核线程的切换和基本调度过程

## 实验内容

在前面的实验中，我们已经完成了物理内存管理和基础页表机制的实现，使内核具备了对物理内存页的分配与管理能力，并能够建立起虚拟地址到物理地址的基本映射结构。但当前系统仍然只能以单一执行流的方式运行，无法并发执行多个任务，也尚未体现虚拟内存机制在进程或线程隔离中的作用。

本实验将在此基础上进一步扩展，完成以下两方面内容：

首先，**进一步完善虚拟内存管理，实现基本的地址空间结构**。通过引入虚拟内存描述结构，管理进程或线程的虚拟地址空间布局，为每个执行实体提供逻辑上的运行空间。与后续实验中的缺页异常和页面置换不同，本实验中的虚拟内存仍采用**预映射方式**，即在建立地址空间时一次性完成所有需要的页表映射，不涉及按需分配或页面置换。

其次，**引入内核线程机制，实现多执行流并发运行能力**。内核线程是一种特殊形式的“进程”。当一个程序加载到内存中运行时，首先通过ucore OS的内存管理子系统分配合适的空间，然后就需要考虑如何分时使用CPU来“并发”执行多个程序，让每个运行的程序（这里用线程或进程表示）“感到”它们各自拥有“自己”的CPU。本实验将实现线程控制块、上下文切换和调度器等内容，从而实现多线程并发执行，使内核能够调度多个执行实体轮流使用 CPU 运行。

内核线程与用户进程的区别如下：

| 比较项   | 内核线程         | 用户进程                   |
| -------- | ---------------- | -------------------------- |
| 运行模式 | 仅在内核态运行   | 在用户态和内核态之间切换   |
| 地址空间 | 共享内核地址空间 | 拥有独立的用户虚拟地址空间 |

通过本实验，系统将从“单一执行流的内核”发展为“支持多线程调度的内核”，并完成基本的虚拟内存环境框架搭建，为后续实现用户进程、系统调用、缺页异常处理和页面置换等功能奠定基础。

需要注意的是，在ucore的调度和执行管理中，**对线程和进程做了统一的处理**。且由于ucore内核中的所有内核线程共享一个内核地址空间和其他资源，所以这些内核线程从属于同一个唯一的内核进程，即ucore内核本身。

## 实验过程

### 练习0：填写已有实验

相关内容均已按照Lab2，Lab3的实验填写到了Lab4上，运行结果如下(此时还没有填写Lab4的其他练习，因此进程创建失败，这很正常)：

![image-20251113172521143](第四次实验报告.assets/image-20251113172521143.png)



### 练习1：分配并初始化一个进程控制块（需要编码）

我们补全的alloc_proc函数代码如下：

```c
static struct proc_struct *
alloc_proc(void)
{
    struct proc_struct *proc = kmalloc(sizeof(struct proc_struct));
    if (proc != NULL)
    {
        proc->state = PROC_UNINIT;
        proc->pid = -1;
        proc->runs = 0;
        proc->kstack = 0;
        proc->need_resched = 0;
        proc->parent = NULL;
        proc->mm = NULL;
        memset(&proc->context, 0, sizeof(struct context));
        proc->tf = NULL;
        proc->pgdir = boot_pgdir_pa;
        proc->flags = 0;
        memset(&proc->name,0,PROC NAME LEN);
    }
    return proc;
}
```

函数一开始会使用**kmalloc**函数来申请一块结构体**proc_struct**大小的内存块，这块内存块作为进程控制块，需要被正确的初始化才能够使用。接下来是对它每一个字段初始化值的原因：

* **state**：该值有四个枚举值，分别是PROC_UNINIT未初始化态，PROC_SLEEPING非运行态（可能是就绪态或者阻塞态），PROC_RUNNABLE运行态，PROC_ZOMBIE终止态，因为此时该进程刚刚被创建，所有值都还未设，因此它只能是未初始化态，不是PROC_SLEEPING，更不是PROC_RUNNABLE或PROC_ZOMBIE态。
* **pid**：首先，一个进程的PID值会由后续的**get_pid**函数指定，在初始化函数中我们不需要关心，因此问题就变成了初始化为-1还是0的问题。在ucore中，闲逛进程的PID已经被初始化为了0，0是一个真正的存在的进程，因此初始化不应是一个已经存在的进程的PID，所以这里初始化为-1。
* **runs**：这个字段指示的是该进程的运行次数，此时这个进程还在创建过程中，因此该值当然是0.
* **kstack**：该值是一个地址，指向为进程独立分配的内核栈空间，这里是初始化，内核栈空间还没有分配，因此初始化为0即可，后续代码idleproc->kstack == 0也证明了这一点。
* **need_resched**：该值用于指定进程是否需要被调度出CPU，0是不需要1是需要。由初始化的状态PROC_UNINIT可知，这个值显然要设置为0，一个没被创建好的进程不可能需要被调出CPU
* **parent**：该指针指向这个进程的父进程，这里要初始化为NULL，因为后续会有另外的函数来定义这个值，现在我们还一无所知。
* **mm**：内核线程共享内核地址空间，无需独立内存管理结构，如果是用户进程，那么会使用**copy_mm**函数去复制父进程的内存，当然本次实验还不涉及。
* **context**：进程上下文，在进程创建阶段，该进程还没有任何的上下文，因此全部清0即可，避免后续使用因随机值导致异常。
* **tf**：指向中断帧数据结构**trapframe**，用于保存中断或系统调用时的硬件状态，此时新进程处在初始化，未触发中断，因此该值肯定是NULL
* **pgdir**：页表基地址，因为内核线程共享内核页表，因为**boot_pgdir_pa**是启动时初始化的页表物理地址，内核线程直接使用全局页表，无需独立地址空间，因此直接赋值**boot_pgdir_pa**，后续**proc_init**函数检查内核进程控制块的pgdir值是否是**boot_pgdir_pa**也证明了这一点。
* **flags**：进程标志位。这里直接清0即可，后续有需求后续会进行相关设置。
* **name**：进程名。此时还未指定，因此直接初始化为空字符串。

#### 请说明proc_struct中`struct context context`和`struct trapframe *tf`成员变量含义和在本实验中的作用是啥？

* **struct context context**：这个成员变量保存了一个进程的运行上下文。什么是进程的运行上下文？简言之，一个进程在运行到某个状态时，很可能因为主动或被动的原因需要被CPU调出，此时这个进程若想下次调入CPU时还能正确运行，就必须保存当前该进程的运行状态，比如一些关键寄存器的值。

  数据结构context 包含了被调用者保存寄存器s0-s11，还包含了返回地址寄存器ra和栈地址寄存器sp，这些寄存器构成了一个进程运行的上下文。

  因此，context用于进程间的上下文切换，即当调度器决定切换到另一个进程时，保存当前进程的执行状态（主要是ra和sp等关键寄存器和被调用者保存寄存器，并不是所有寄存器），并用于后续恢复目标进程的状态。

* **struct trapframe *tf**：这个数据结构我们并不陌生，在Lab3探索中断和异常机制时我们曾频繁的接触它，这个数据结构保存了中断或系统调用发生时的硬件状态。在一个进程运行时，其不仅要主动或者被动的被调入调出CPU(也就是进程调度)，还可能会产生一些中断和异常行为，此时CPU会暂停当前执行进程手中的活，转而去执行相对应的处理程序，这个时候就需要**tf**来保存硬件状态，以供处理程序完成之后继续进程的执行。

  因此，tf用于处理中断和系统调用（或是触发异常）。当发生中断或系统调用时，硬件会保存部分状态到trapframe，然后进入内核态处理。处理完成后，通过`tf`恢复进程的执行环境。

  

### 练习2：为新创建的内核线程分配资源（需要编码）

创建一个内核线程需要分配和设置好很多资源。kernel_thread函数通过调用do_fork函数完成具体内核线程的创建工作。do_kernel函数会调用alloc_proc函数来分配并初始化一个进程控制块，但alloc_proc只是找到了一小块内存用以记录进程的必要信息，并没有实际分配这些资源。ucore一般通过do_fork实际创建新的内核线程。do_fork的作用是，创建当前内核线程的一个副本，它们的执行上下文、代码、数据都一样，但是存储位置不同。因此，我们实际需要"fork"的东西就是stack和trapframe。在这个过程中，需要给新内核线程分配资源，并且复制原进程的状态。你需要完成在kern/process/proc.c中的do_fork函数中的处理过程。它的大致执行步骤包括：

调用alloc_proc，首先获得一块用户信息块。

为进程分配一个内核栈。
复制原进程的内存管理信息到新进程（但内核线程不必做此事）

复制原进程上下文到新进程

将新进程添加到进程列表

唤醒新进程

返回新进程号

请在实验报告中简要说明你的设计实现过程。请回答如下问题：

请说明ucore是否做到给每个新fork的线程一个唯一的id？请说明你的分析和理由。

#### 解答

我实现的do_fork函数如下:

    int do_fork(uint32_t clone_flags, uintptr_t stack, struct trapframe *tf)
    {
        int ret = -E_NO_FREE_PROC;
        struct proc_struct *proc;
        if (nr_process >= MAX_PROCESS)
        {
            goto fork_out;
        }
        ret = -E_NO_MEM;
        

        //    1.分配并初始化进程控制块
        proc = alloc_proc();
        if (proc == NULL){
            goto fork_out;
        }
        //    2. 分配并初始化内核栈（setup_stack函数）
        if (setup_kstack(proc) != 0){
            goto bad_fork_cleanup_proc;
        }

        //    3. 根据clone_flags决定是复制还是共享内存管理系统（copy_mm函数）
        if (copy_mm(clone_flags, proc) != 0){
            goto bad_fork_cleanup_kstack;
        }


        //    4. 设置进程的中断帧和上下文（copy_thread函数）
        copy_thread(proc, stack, tf);
        //    5.把设置好的进程加入链表
        proc->pid = get_pid();       // 分配唯一 pid
        proc->parent = current;      // 父进程是 current

        list_add(&proc_list, &proc->list_link); // 加入进程链表
        hash_proc(proc);                         // 加入 hash 表

        nr_process++;  // 进程数量 +1

        //    6. 将新建的进程设为就绪态

        proc->state=PROC_RUNNABLE;
        //    7.将返回值设为线程id
        ret = proc->pid;
        
    fork_out:
        return ret;

    bad_fork_cleanup_kstack:
        put_kstack(proc);
    bad_fork_cleanup_proc:
        kfree(proc);
        goto fork_out;
    }

接下来我将解释这个函数的作用。首先可以知道，do_fork函数是在kernel_thread这个函数里被调用的，如下：

    int kernel_thread(int (*fn)(void *), void *arg, uint32_t clone_flags)
    {
        struct trapframe tf;
        memset(&tf, 0, sizeof(struct trapframe));
        tf.gpr.s0 = (uintptr_t)fn;
        tf.gpr.s1 = (uintptr_t)arg;
        tf.status = (read_csr(sstatus) | SSTATUS_SPP | SSTATUS_SPIE) & ~SSTATUS_SIE;
        tf.epc = (uintptr_t)kernel_thread_entry;
        return do_fork(clone_flags | CLONE_VM, 0, &tf);
    }

这个函数的作用是是在操作系统内核层面创建一个新的内核线程，来执行fn(arg)。即传入的第一个参数为函数指针，第二个是函数参数，第三个是标志符号。然后定义一个trapframe用来保存线程上下文。

然后保存函数指针和参数，再读取RISC-V的sstatus寄存器，并且设置上一个特权模式为内核模式，设置上一个状态可以响应中断，屏蔽 SIE，当前状态不响应中断。

然后指定新线程启动时的入口函数，最后调用do_fork创建线程并返回。

接下来开始分析do_fork的实现逻辑，传入了三个参数，第一个是clone_flags标志，并且父子进程共享内存空间，第二个是0，因为内核线程没有用户态栈，它永远只在内核态运行，所以用户态栈地址没有意义，最后是CPU上下文。

然后开始具体的代码部分，首先判断还能不能创建新进程，如果可以，先用alloc_proc()分配并初始化一个进程控制块。第二步，使用setup_kstack函数为新进程分配内核栈，第三步是根据clone_flags决定是复制还是共享内存管理系统，这里使用了copy_mm函数，因为当前进程是内核线程，没有用户态地址空间，所以不需要复制用户态内存。第四步，使用copy_thread函数，拷贝父进程的 trapframe，然后判断，如果 esp 为 0（内核线程），就用trapframe本身地址作为栈指针，如果是用户进程，使用父进程传过来的 esp，然后初始化上下文context，ra（返回地址）设置为 forkret，表示新进程第一次被调度时，会执行forkret函数，sp（上下文栈指针）指向trapframe，让线程从 trapframe中恢复寄存器，正确开始执行。第五步，先用 get_pid()函数为新进程创建一个pid，然后把父进程设置为当前运行的进程，最后把新进程的指针加到链表和哈希表里，并让进程数量加一。第六步，把新进程的状态设置为PROC_RUNNABLE。第七步，也是最后一步，把返回值ret设置为新进程的pid。

这样就完成了do_fork函数的功能。

#### 请说明ucore是否做到给每个新fork的线程一个唯一的id？请说明你的分析和理由。

可以做到给每个新fork的线程一个唯一的id，理由如下：

首先，根据上边的讲解，我可以知道，新fork的线程的id是通过get_pid()函数分配的，而get_pid()函数通过维护静态变量last_pid来记录上一次分配的PID，并在每次调用时递增。如果PID超过上限MAX_PID，则从1开始回绕。

在分配之前，函数会遍历当前的进程链表proc_list，检查PID是否已被占用，如果冲突则跳过，直到找到一个未被占用的PID返回，从而保证每个活着的进程或线程都拥有唯一的 PID。

因此，可以做到给每个新fork的线程一个唯一的id。


### 练习3：编写proc_run 函数（需要编码）
#### proc_run用于将指定的进程切换到CPU上运行。它的大致执行步骤包括：
* 检查要切换的进程是否与当前正在运行的进程相同，如果相同则不需要切换。
* 禁用中断。你可以使用/kern/sync/sync.h中定义好的宏local_intr_save(x)和local_intr_restore(x)来实现关、开中断。
* 切换当前进程为要运行的进程。
* 切换页表，以便使用新进程的地址空间。/libs/riscv.h中提供了lsatp(unsigned int pgdir)函数，可实现修改SATP寄存器值的功能。
* 实现上下文切换。/kern/process中已经预先编写好了switch.S，其中定义了switch_to()函数。可实现两个进程的context切换。
* 允许中断。

#### 请回答如下问题：
##### 在本实验的执行过程中，创建且运行了几个内核线程？
##### 完成代码编写后，编译并运行代码：make qemu

题目中已经给出了我们要进行的具体操作，那么我们来补全proc.c中的proc_run函数。
```c
// proc_run - make process "proc" running on cpu
// NOTE: before call switch_to, should load  base addr of "proc"'s new PDT
void proc_run(struct proc_struct *proc)
{
    if (proc != current)
    {
        // LAB4:EXERCISE3 2313752
        /*
         * Some Useful MACROs, Functions and DEFINEs, you can use them in below implementation.
         * MACROs or Functions:
         *   local_intr_save():        Disable interrupts
         *   local_intr_restore():     Enable Interrupts
         *   lsatp():                   Modify the value of satp register
         *   switch_to():              Context switching between two processes
         */        
        bool intr_flag;
        // 1. 禁用中断，以保证上下文切换的原子性
        local_intr_save(intr_flag);
        // 2. 切换当前进程指针,保存旧进程的引用，以便传递给 switch_to
        struct proc_struct *prev = current;
        current = proc;
        // 3. 切换页表,lsatp 函数会将 proc->pgdir 的值加载到 satp 寄存器中，并刷新 TLB，使新的地址映射生效。
        lsatp(proc->pgdir);
        // 4. 切换上下文,调用 switch_to 汇编函数，保存 prev 进程的上下文，恢复 proc 进程的上下文。这个函数执行后，CPU 的寄存器状态将变为 proc 进程上次被切换出去时的状态。
        switch_to(&(prev->context), &(proc->context));
        // 5. 允许中断,下文切换完成后，重新开启中断。
        local_intr_restore(intr_flag);
    }
}
```
这里我们逐行说明一下：

1. if (proc != current):  
这是原来的代码，是一个优化和防止错误的检查。如果要切换到的进程就是当前正在运行的进程，那么什么都不用做，直接返回即可。
1. bool intr_flag; 和 local_intr_save(intr_flag);:  
local_intr_save 是一个宏，它会禁用当前 CPU 的中断，并将中断禁用前的状态保存到 intr_flag 变量中。这里要禁用中断，是因为进程切换是一个需要原子执行的操作。如果在切换过程中（比如刚保存了旧进程的上下文，还没恢复新进程的上下文时）发生了中断，可能会导致系统状态不一致，引发严重错误。禁用中断可以保证整个切换过程不受干扰。
那么下面我们看一下local_intr_save 宏的实现:(在sync.h中)
```c
static inline bool __intr_save(void) {
    if (read_csr(sstatus) & SSTATUS_SIE) {
        intr_disable();
        return 1;
    }
    return 0;
}

#define local_intr_save(x) \
    do {                   \
        x = __intr_save(); \
    } while (0)
#define local_intr_restore(x) __intr_restore(x);
```
这里先是定义了一个静态内联函数__intr_save，先读取sstatusji值，并判断当前中断是否处于开启状态。如果处于开启状态，则调用 intr_disable() 禁用中断，并返回 1。否则，返回 0。  
那么最后的结果就是禁用了中断，并且保存了禁用前的中断状态。  
后面是定义了一个宏 local_intr_save，这个宏就是调用刚才的_intr_save函数，并把结果（禁用前的状态）保存到 x 中，定义这个宏是为了方便使用的。

3. struct proc_struct *prev = current; current = proc;:  
我们首先将当前进程 current 的指针保存到 prev 变量中，因为接下来我们需要用它来调用 switch_to。  
然后，将全局变量 current 更新为指向即将运行的新进程 proc。这一步非常关键，它告诉操作系统内核，从现在开始，current 就代表这个新进程了。  
4. lsatp(proc->pgdir);:  
这是地址空间切换的核心步骤。lsatp 函数的作用是将参数 proc->pgdir（新进程的页目录表物理地址）写入到 RISC-V 架构的satp寄存器中。  
```c
static inline void
lsatp(unsigned int pgdir)
{
  write_csr(satp, SATP32_MODE | (pgdir >> RISCV_PGSHIFT));
}
```
写入 satp 寄存器后，mmu就会使用新的页目录表来进行虚拟地址到物理地址的转换。这意味着，接下来 CPU 执行的指令和访问的数据，都将在新进程的地址空间中进行。

5. switch_to(&(prev->context), &(proc->context));:  
这是上下文切换的核心。switch_to 是一个用汇编语言实现的函数（在 switch.S 中）。  
switch_to 函数的具体实现如下。  
```asm
#include <riscv.h>

.text
# void switch_to(struct proc_struct* from, struct proc_struct* to)
.globl switch_to
switch_to:
    # save from's registers
    STORE ra, 0*REGBYTES(a0)
    STORE sp, 1*REGBYTES(a0)
    STORE s0, 2*REGBYTES(a0)
    STORE s1, 3*REGBYTES(a0)
    STORE s2, 4*REGBYTES(a0)
    STORE s3, 5*REGBYTES(a0)
    STORE s4, 6*REGBYTES(a0)
    STORE s5, 7*REGBYTES(a0)
    STORE s6, 8*REGBYTES(a0)
    STORE s7, 9*REGBYTES(a0)
    STORE s8, 10*REGBYTES(a0)
    STORE s9, 11*REGBYTES(a0)
    STORE s10, 12*REGBYTES(a0)
    STORE s11, 13*REGBYTES(a0)

    # restore to's registers
    LOAD ra, 0*REGBYTES(a1)
    LOAD sp, 1*REGBYTES(a1)
    LOAD s0, 2*REGBYTES(a1)
    LOAD s1, 3*REGBYTES(a1)
    LOAD s2, 4*REGBYTES(a1)
    LOAD s3, 5*REGBYTES(a1)
    LOAD s4, 6*REGBYTES(a1)
    LOAD s5, 7*REGBYTES(a1)
    LOAD s6, 8*REGBYTES(a1)
    LOAD s7, 9*REGBYTES(a1)
    LOAD s8, 10*REGBYTES(a1)
    LOAD s9, 11*REGBYTES(a1)
    LOAD s10, 12*REGBYTES(a1)
    LOAD s11, 13*REGBYTES(a1)

    ret
```
这段代码就是将需要保存的寄存器进行保存和调换。其中的a0和a1是RISC-V 架构中通用寄存器，a0指向原进程，a1指向目的进程。  
寄存器可以分为调用者保存（caller-saved）寄存器和被调用者保存（callee-saved）寄存器，线程切换在一个函数也就是我们的proc_run中，所以编译器会自动帮助我们生成保存和恢复调用者保存寄存器的代码，在实际的进程切换过程中我们只需要保存被调用者保存寄存器。    
由于我们在初始化时把上下文的ra寄存器设定成了forkret函数的入口，所以这里会返回到forkret函数。forkrets函数很短，位于kern/trap/trapentry.S：
```
    .globl forkrets
forkrets:
    # set stack to this new process's trapframe
    move sp, a0
    j __trapret
```
这里把传进来的参数，也就是进程的中断帧放在了sp，这样在__trapret中就可以直接从中断帧里面恢复所有的寄存器。

6. local_intr_restore(intr_flag);:  
当 switch_to 返回时，意味着上下文切换已经完成。  
local_intr_restore 宏会根据之前保存的 intr_flag 变量的值，来决定是否重新开启中断。如果切换前中断是开启的，那么现在就重新开启；如果切换前就是关闭的，那就保持关闭。这保证了中断状态的正确恢复。  

**总结**  
我们的proc_run 函数体现了进程切换的三个层面：
* 内核视角切换：current = proc;
* 地址空间切换：lsatp(proc->pgdir);
* CPU 执行上下文切换：switch_to(...)  
通过这三个步骤，操作系统成功地将 CPU 的控制权从一个进程交给了另一个进程，实现了多任务并发。

下面回答本练习中所提到的问题：
##### 在本实验的执行过程中，创建且运行了几个内核线程？
本实验中创建并运行了 2 个内核线程，分别是 idleproc和 initproc。
1. idleproc
   是一个占位线程，他是在 proc_init 函数中通过 alloc_proc() 分配并初始化，PID 为 0。状态设为 PROC_RUNNABLE，内核栈使用 bootstack（启动栈），是系统启动后第一个运行的线程，同时也是找不到其他状态为PROC_RUNNABLE的进程时的保底线程。
2. initproc
   是在 proc_init 中通过 kernel_thread(init_main, "Hello world!!", 0) 创建，PID 为 1。由 kernel_thread 封装 do_fork 实现创建，最终通过调度器获得 CPU 执行权，运行 init_main 函数（在本实验中是输出 “Hello world!!” 等信息）。是系统中第一个实际执行任务的内核线程，用于验证线程创建与调度机制的正确性。
##### 完成代码编写后，编译并运行代码：make qemu
运行结果如下：

![image-20251113172521143](第四次实验报告.assets/练习三.png)

可以看到正确输出了initproc进程中的 Hello world!! 等内容。说明完成了进程的切换。

### 扩展练习 Challenge：
**1. 说明语句local_intr_save(intr_flag);....local_intr_restore(intr_flag);是如何实现开关中断的？**

**2. 深入理解不同分页模式的工作原理（思考题）**
**get_pte()函数（位于kern/mm/pmm.c）用于在页表中查找或创建页表项，从而实现对指定线性地址对应的物理页的访问和映射操作。这在操作系统中的分页机制下，是实现虚拟内存与物理内存之间映射关系非常重要的内容。**
* get_pte()函数中有两段形式类似的代码， 结合sv32，sv39，sv48的异同，解释这两段代码为什么如此相像。
* 目前get_pte()函数将页表项的查找和页表项的分配合并在一个函数里，你认为这种写法好吗？有没有必要把两个功能拆开？


## 列出你认为本实验中重要的知识点，以及与对应的OS原理中的知识点，并简要说明你对二者的含义，关系，差异等方面的理解（也可能出现实验中的知识点没有对应的原理知识点）


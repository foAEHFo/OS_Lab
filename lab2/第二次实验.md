 <h1 align="center"> Lab2:物理内存和页表 </h1>

 <div align="center">

张德民 刘越帅 欧广元

</div>

## 实验目的
理解页表的建立和使用方法。

理解物理内存的管理方法。

理解页面分配算法。

## 实验内容
实验一过后大家做出来了一个可以启动的系统，实验二主要涉及操作系统的物理内存管理。操作系统为了使用内存，还需高效地管理内存资源。本次实验我们会了解如何发现系统中的物理内存，然后学习如何建立对物理内存的初步管理，即了解连续物理内存管理，最后掌握页表相关的操作，即如何建立页表来实现虚拟内存到物理内存之间的映射，帮助我们对段页式内存管理机制有一个比较全面的了解。本次的实验主要是在实验一的基础上完成物理内存管理，并建立一个最简单的页表映射。

## 实验过程

### 练习1：理解first-fit 连续物理内存分配算法（思考题）
first-fit 连续物理内存分配算法作为物理内存分配一个很基础的方法，需要同学们理解它的实现过程。请大家仔细阅读实验手册的教程并结合kern/mm/default_pmm.c中的相关代码，认真分析default_init，default_init_memmap，default_alloc_pages， default_free_pages等相关函数，并描述程序在进行物理内存分配的过程以及各个函数的作用。 请在实验报告中简要说明你的设计实现过程。请回答如下问题：

你的first fit算法是否有进一步的改进空间？



### 练习2：实现 Best-Fit 连续物理内存分配算法（需要编程）
在完成练习一后，参考kern/mm/default_pmm.c对First Fit算法的实现，编程实现Best Fit页面分配算法，算法的时空复杂度不做要求，能通过测试即可。 请在实验报告中简要说明你的设计实现过程，阐述代码是如何对物理内存进行分配和释放，并回答如下问题：

你的 Best-Fit 算法是否有进一步的改进空间？

对于Best-Fit 连续物理内存分配算法，我们组经过查阅后发现，真实的代码实现和理论上的不太一样，理论上要求是按照空闲区块大小去维护链表，但是实际代码实现(包括助教提供的注释)都是按照地址大小去排列的，只是在分配的时候算法不一样，按照空闲区块大小去维护链表只需要找到第一个满足的就一定是最小的，但是按照地址大小去排列需要全部遍历一遍，但是它们在回收的时候算法也不一致，按照空闲区块大小去维护链表需要把全部区块都扫一遍，而按照地址大小去排列只需要测试前后两个就可以了。在下面我们组将两种算法都实现了：

#### 第一种，按照地址大小维护链表

以下是我们编写的关于Best Fit页面分配算法的实现，我将基于所有有注释"YOUR CODE"的地方依次解释实现过程：

**①best_fit_init_memmap 函数部分代码：**

``````
    for (; p != base + n; p ++) {
        assert(PageReserved(p));
        /*LAB2 EXERCISE 2: 2313180*/ 
        // 清空当前页框的标志和属性信息，并将页框的引用计数设置为0
        p->flags = 0;
        p->property = 0;
        set_page_ref(p, 0);

    }
``````

​	这个函数意在初始化这个页面分配算法，base是当前空闲页块链表的基址，算法for循环遍历每个页，此时当前页指针为p，然后通过给结构体属性flags和property赋值为0的方式，清空了当前页框的标志位和属性信息。

​	仿照之前first fit的算法，这里照样也使用**set_page_ref**函数设置该页引用计数，我们只需要传入当前页指针p，和数字0，以达到清零的作用。



**②best_fit_init_memmap 函数第二处代码：**

``````
while ((le = list_next(le)) != &free_list) {
            struct Page* page = le2page(le, page_link);
            /*LAB2 EXERCISE 2: 2313180*/ 
            // 编写代码
            // 1、当base < page时，找到第一个大于base的页，将base插入到它前面，并退出循环
            // 2、当list_next(le) == &free_list时，若已经到达链表结尾，将base插入到链表尾部
            if (base < page) {
                list_add_before(le, &(base->page_link));
                break;
            }
            else if(list_next(le) == &free_list){
                list_add(le,&(base->page_link));
            }

        }
``````

​	这里的任务是要在链表中插入base指向的那个空闲块。请注意我们为什么要寻找第一个大于base的页，这是因为我们要维护的就是一个块地址递增的链表。

​	这里需要清楚的是page本身指向的就是下一个页框的首地址(同base)，因此比较直接只用base<page即可，如果成立，那么就找到了第一个地址比base大的页框，所以我们需要将base指向的页框插在le指向的块之前（也就是当前这个块之前），所以使用前插入函数：

`list_add_before(le,&(base->page_link));`

例外情况就是当遍历到链表尾的时候，还没有找到这个符合条件的块，那我们直接把base插入到链表尾即可。还有一个问题，这里是调用list_add函数还是list_add_after函数呢，答案是两个都可以，因为list.h中说明了list_add函数的实现就是调用了list_add_after：

``````
static inline void
list_add(list_entry_t *listelm, list_entry_t *elm) {
    list_add_after(listelm, elm);
}
``````

我这里直接使用了list_add。但如果使用list_add_after，可能会更加直观。



**③best_fit_alloc_pages函数部分代码：**

``````
    /*LAB2 EXERCISE 2: 2313180*/ 
    // 下面的代码是first-fit的部分代码，请修改下面的代码改为best-fit
    // 遍历空闲链表，查找满足需求的空闲页框
    // 如果找到满足需求的页面，记录该页面以及当前找到的最小连续空闲页框数量

    //不同于first-fit，这里需要遍历整个空闲链表，找到最小的连续空闲块，并返回该块的首页指针
    unsigned int min = 0xffffffff;
    while((le = list_next(le)) != &free_list){
        struct Page *p = le2page(le, page_link);
        if(p -> property >= n && p -> property < min){
            min = p -> property;
            page = p;
        }
    }
``````

​	如同注释所说，best fit 要求找到一个符合取用大小但尽量可能小的块，这里可以先设置一个变量min，初始值直接赋一个极大值(方便后面匹配到第一个符合取用大小的块的时候就变为那个块的大小)。

改变逻辑判断条件为：

`if(p -> property >= n && p -> property < min)`

​	前一个要求符合取用条件，后一个要求这个块要比上一个符合条件的块更小，都满足的话才能执行里面的语句，分别是记录当前符合条件块的最小值，和赋值page。

​	与first fit不同的是，这里不需要break，因此要尽可能找到最小的块，因此时间复杂度上不可避免要比first_fit更大一些。如果从头到尾都没有找到符合条件的块，那么page保持NULL返回。

**④best_fit_free_pages函数部分代码：**

``````
    /*LAB2 EXERCISE 2: 2313180*/ 
    // 编写代码
    // 具体来说就是设置当前页块的属性为释放的页块数、并将当前页块标记为已分配状态、最后增加nr_free的值

    base->property = n;
    SetPageProperty(base);
    nr_free += n;
``````

n是调用方传来的释放的内存大小，因此base的property属性理所应当被设置为n，同时别忘了给nr_free加上n（nr_free表示这个链表中的所有块的大小）。由SetPageProperty函数的代码：

`SetPageProperty(page) ((page)->flags |= (1UL << PG_property))`

利用该函数可以把这个页的flags设置为1，这表示空闲状态。这是添加入链表的前提。

**⑤best_fit_free_pages函数第二部分代码：**

``````
    list_entry_t* le = list_prev(&(base->page_link));
    if (le != &free_list) {
        p = le2page(le, page_link);
        /*LAB2 EXERCISE 2: 2313180*/ 
        // 编写代码
        // 1、判断前面的空闲页块是否与当前页块是连续的，如果是连续的，则将当前页块合并到前面的空闲页块中
        if(p+p->property == base){
            // 2、首先更新前一个空闲页块的大小，加上当前页块的大小
            p->property += base->property;
            // 3、清除当前页块的属性标记，表示不再是空闲页块
            ClearPageProperty(base);
            // 4、从链表中删除当前页块
            list_del(&(base->page_link));
            // 5、将指针指向前一个空闲页块，以便继续检查合并后的连续空闲页块
            base = p;
        }
    }
``````

这段代码意在将释放回来的块与可能的前块合并，总体上和first fit中的过程是一致的，这里不赘述了。



最后赋上算法测试结果（通过25个测试点）：

<p align="center">
  <img src="./第二次实验.assets/屏幕截图 2025-10-18 172607-1760779604676-2.png" alt="figure">
</p>

#### 第二种，按照区块大小维护链表

对于这个实现，有些部分没办法按照助教提供的注释写，所以并没有保留这些注释。

**best_fit_init_memmap 函数**

    static void
    best_fit_init_memmap(struct Page *base, size_t n) {
        assert(n > 0);
        struct Page *p = base;
    
        for (; p != base + n; p ++) {
            assert(PageReserved(p));
            /*LAB2 EXERCISE 2: 2312141*/ 
            // 清空当前页框的标志和属性信息，并将页框的引用计数设置为0
            p->flags = p->property = 0; // 清除标志位和属性
            set_page_ref(p, 0);         // 将引用计数设置为0
        }
    
        base->property = n;
        SetPageProperty(base);
        nr_free += n;
    
        if (list_empty(&free_list)) {
            list_add(&free_list, &(base->page_link));
        } else {
            list_entry_t* le = &free_list;
            while ((le = list_next(le)) != &free_list) {
                struct Page* page = le2page(le, page_link);
                /*LAB2 EXERCISE 2: 2312141*/ 
                // 编写代码
                if (base->property <= page->property) {
                    list_add_before(le, &(base->page_link));
                    break;
                } else if (list_next(le) == &free_list) {
                    list_add(le, &(base->page_link));
                    break;
                }
            }
        }
    }

如上边代码，清空当前页框的标志和属性信息，并将页框的引用计数设置为0这一部分和first-fit算法是一样的，主要是后边的插入算法与first-fit不同，区别在于判断条件是`base->property <= page->property`,比较当前区块的大小，从而实现维护一个按照内存大小排列的链表，其余保持一致。

**best_fit_alloc_pages 函数**

下边只解释不同的地方：

    // 遍历空闲链表寻找最小适配块
      /*LAB2 EXERCISE 2: 2312141*/ 
      // 下面的代码是first-fit的部分代码，请修改下面的代码改为best-fit
      // 遍历空闲链表，查找满足需求的空闲页框
      // 如果找到满足需求的页面，记录该页面以及当前找到的最小连续空闲页框数量
    
      while ((le = list_next(le)) != &free_list) {
          struct Page *p = le2page(le, page_link);     
          if (p->property >= n) {
              page = p;
              min_size = p->property;
              break;
          }
      }

如上边代码，是在寻找合适的区块进行分配，这里的实现和first-fit基本一样，但是和我们的第一种方法不同，不需要遍历所有的区块，因为是按照大小排列的，所以找到的第一个满足条件的就一定是最小的，此时直接break退出循环即可。

    // 插入剩余部分
            list_entry_t *le_2 = &free_list;
            while ((le_2 = list_next(le_2)) != &free_list) {
                struct Page* page_2 = le2page(le_2, page_link);
                if (p->property <= page_2->property) {
                    list_add_before(le_2, &(p->page_link));
                    break;
                } else if (list_next(le_2) == &free_list) {
                    list_add(le_2, &(p->page_link));
                    break;
                }
        }

分配完以后，对于剩余部分的重新插入也不同，我们需要重新遍历一遍这个链表，找到第一个比剩余区块大的节点，然后插入到它的前边就行。如果没有找到，就插入到链表最后即可。

注意这一部分是不需要进行合并的，因为剩余部分不可能和任何的其余区块合并，它前边的区块被分配走了，后边的因为最初在链表里就没有合并，重新插入当然也不可能合并了。

**best_fit_free_pages 函数**

这个部分和第一种方法就完全不一样了，第一种需要先按照地址大小插入，然后再和前后两个块尝试合并，但是这个第二种方法需要先去遍历链表，进行合并，然后再重新插入。

    list_entry_t *le = &free_list;
        // 尝试与前面的块合并
        while ((le = list_next(le)) != &free_list) {
            struct Page *page = le2page(le, page_link);
            if (base > page) {
                if (page + page->property == base) {
                    page->property += base->property;
                    ClearPageProperty(base);
                    list_del(&(page->page_link));
                    base = page;
                    break;
                }
            }
        }
如上边代码，释放的块首先尝试去找地址在它前边的块合并，因为我是按照内存大小排列的，所以需要把链表全部扫一遍，只要是地址低于释放区块的，都尝试进行合并，如果成功，把匹配成功的块从链表里删除，并更新指针，然后break。

      // 尝试与后面的块合并
      le = &free_list;
      while ((le = list_next(le)) != &free_list) {
          struct Page *page = le2page(le, page_link);
          if (base < page) {
              if (base + base->property == page) {
                  base->property += page->property;
                  ClearPageProperty(page);
                  list_del(&(page->page_link));
                  break;
              }
          }
      }

如上边代码，是和后边的块进行合并，逻辑和上边的基本一样，只不过改为只要是地址高于释区块的，都尝试进行合并。

事实上这俩遍历是可以合并一起处理的，不过我在实现的时候为了讲解方便，还有代码的可读性，就先把这个遍历拆开了。

    // 插入base到链表中（保持按大小排序）
        if (list_empty(&free_list)) {
            list_add(&free_list, &(base->page_link));
        } else {
            list_entry_t *le_2 = &free_list;
            bool inserted = 0;
            while ((le_2 = list_next(le_2)) != &free_list) {
                struct Page *page_2 = le2page(le_2, page_link);
                if (base->property <= page_2->property) {
                    list_add_before(le_2, &(base->page_link));
                    inserted = 1;
                    break;
                } else if (list_next(le_2) == &free_list) {
                    list_add(le_2, &(base->page_link));
                    inserted = 1;
                    break;
                }
            }
        }
最后一部分就是将合并好的区块重新插入到链表里边，这里依旧是按照大小去比较，找到第一个大于要插入区块的区块，然后插入到前边就行，否则插到最后。

在实现这个代码的过程里遇见了很多问题，事实上我在写完后发现这个代码逻辑其实并不难，但是在具体自己写的时候出了很多小问题，只能一点一点去改，以下附一张调试代码的时候的调试输出图(上边的代码为了讲解，把调试部分删除了)：


<p align="center">
  <img src="figure/zdm_figure4.png" alt="figure">
</p>

最后，附上测试通过图片：

<p align="center">
  <img src="figure/zdm_figure5.png" alt="figure">
</p>



对于算法的优化，刚才说到Best-Fit算法需要遍历来找到目标块，这是一个线性的时间复杂度，但如果我们不维护一个链表，转而维护的是一个二叉树，对于任意一个非叶子节点来说，内存大小小的是左孩子，大的是右孩子，通过这种方式可以更快的找到目标块，将时间复杂度降到对数级。

此外第二种实现方法里我们也提到了，可以把两遍遍历合并为一遍。

所以当然是有改进空间的了！

### 扩展练习Challenge：buddy system（伙伴系统）分配算法（需要编程）
Buddy System算法把系统中的可用存储空间划分为存储块(Block)来进行管理, 每个存储块的大小必须是2的n次幂(Pow(2, n)), 即1, 2, 4, 8, 16, 32, 64, 128...

参考伙伴分配器的一个极简实现， 在ucore中实现buddy system分配算法，要求有比较充分的测试用例说明实现的正确性，需要有设计文档。

## buddy system分配算法的实现

### 简介

​	在Best Fit能否进一步优化的问题中，我们提到可以使用二叉树这么一个数据结构来优化寻找最小合适块的算法。实际上，进一步的，如果我们一开始开辟的内存大小就是2的幂次方，那么我们就可以很顺利的一直二分内存，直到1个单位内存。也就是说，这个时候不仅可以分配上达到O(log n)的best fit，释放上也能通过递归溯源的形式，达到O(log n)的时间复杂度。这就是buddy system实现前的大致思考。

更具体一点，如下图：

![image-20251017141824765](第二次实验.assets/image-20251017141824765.png)

假设一开始的内存是16个单位大小，那么根节点0此时代表整块内存。下一步一分为二，分成两块大小为8的内存，分别用index 1，2 来表示节点。以此类推，我们能够定义：

**2*页数 -1**

个节点，每个节点只包含自己的Node_size大小，我们因此可以维护一个二叉树来实现内存分配和释放的功能。

**但是**再仔细想想，这样的实现，如果照搬到ucore中，是不是能在时空效率上都达到较优呢，正如OS lab中提供的的简易源码实现中[wuwenbin/buddy2: buddy内存分配器实现](https://github.com/wuwenbin/buddy2)

我们要维护一个大小为2*size-1的线性表，这无疑是非常大的。因为经过前面的实验我们了解到，系统一开始一共会给我们16384个物理页表让我们维护，就算每个节点只有4B大小，也需要至少 2_16 次方大小的空间，这相当于64KB的内存都用来存一个线性表。

所以为了在ucore上更好的实现buddy system，我们可以充分利用系统已经实现好的Page数据结构和双向链表数据结构，先展示我们的数据结构：

``````
typedef struct{
    unsigned int max;
    list_entry_t array[15]; // 代表了阶数最多到14
    unsigned int free;
    // max用于存储最大页数；
    // array[i]维护的是第i阶所有空闲(还能分配出去)的块
    // free用于存储当前空闲页框的个数
}Buddy_system;
``````

实际上，在我们实现的数据结构中，若设初始化的size = 2_n 次方，那么二叉树实际变成了这样：

![image-20251018151058534](第二次实验.assets/image-20251018151058534.png)

每个阶层都使用一个双向链表来维护，只不过这次我们不显式维护所有节点，而是只维护已经被切分出来并且还是空闲的节点，使用array[i]即可O(1)的访问到第一个空闲的大小为2_i 次方个物理页的块。也就是说，一开始时，根节点就代表整个内存块了。

至于为什么只用初始化array大小为15？当然是因为16384 = 2_14。所以max最大只能是14，因此array[15]是完全够的。

数据结构介绍完毕，接下来具体的介绍该怎么实现初始化，分配和释放。

#### ① buddy system初始化函数

```c
static void // 初始化伙伴内存分配系统
buddy_system_init(void)
{
    for (int i = 0; i < MAX_ORDER + 1; i++)
    {
        list_init(&buddy.array[i]);
    }
    buddy.free = 0;
    buddy.max = 0;
    // 调用list_init函数初始化每一个阶层的链表，并且把free和max值都设为0
}
```

C没有面向对象，因此需要单独写一个函数来初始化buddy_system。只需要调用list_init初始化每一层的双向链表即可，这里的MAX_ORDER是一个定义为14的宏。并且max和free都要初始化为0。



#### ② 内存初始化函数

```c
static void
buddy_system_init_memmap(struct Page *base, size_t n)
{
    // 确保输入合法性
    assert(base != NULL && n > 0);
    // 伙伴系统只能接受2的幂次方个物理页，因此要对n进行第一步处理
    size_t pageNumber = correct_n(n);
    // 得到我们要管理的物理页的数量pageNumber，然后要获得它的阶数
    unsigned int order = getOrderOfTwo(pageNumber);

    // 然后要初始化传入的这块内存中的所有物理页
    for (struct Page *p = base; p != base + pageNumber; p++)
    {
        assert(PageReserved(p));
        // 清除所有flag标记
        p->flags = 0;
        // 全部初始化为非头页
        p->property = -1;
        // 将当前页的引用计数设置为0
        set_page_ref(p, 0);
    }
    // 赋值buddy system
    list_add(&buddy.array[order], &(base->page_link));
    buddy.free = pageNumber;
    buddy.max = pageNumber;

    // 现在开始，Page的property属性代表当前物理页的阶数
    base->property = order;
    SetPageProperty(base); // 设置对应的属性
    return;
}
```

correct_n是一个辅助函数，意在获取最接近n但小于n的一个2的幂次方数，这是因为buddy_system只能接受2的幂次方大小物理页内存的初始化。

getOrderOfTwo函数用于获取一个数是2的几次方，这一点是为了确定根节点要存放的位置，毕竟获取到的order是多少，根节点就在第几个阶层。

确定这些之后，就可以使用list_add函数将根节点插入正确位置的链表，并且free和max都初始化为最大页数。

值得注意的是，Page的property属性，在我们的维护下，不再表示

```the num of free block
 // the num of free block
```

而是表示你这个页在第几阶层。



#### ③ 分配函数

```c
static struct Page *
buddy_system_alloc_pages(size_t n)
{
    // 输入合法性检测
    if (n > buddy.free || n <= 0)
    {
        // 如果请求的页数超出剩余的页数或者n<=0，直接返回NULL
        return NULL;
    }
    struct Page *ret = NULL; // 初始化返回值
    // 与初始化的时候不一样，此时我们需要找到一个最接近但大于等于n的2的幂数
    size_t pageNumber = correct_n(n);
    if (pageNumber != n)
    {
        pageNumber *= 2;
    }
    // 获取分配页数对应的阶数
    unsigned int order = getOrderOfTwo(pageNumber);

    // 现在开始分配正确的块
    while (1)
    // 为什么这里直接死循环寻找呢
    // 因为如果n <= buddy.free,那么就一定可以获取到一个能够分配的块
    {
        if (!list_empty(&buddy.array[order]))
        {
            // 如果当前阶数对应的链表非空，则进行分配
            ret = le2page(list_next(&buddy.array[order]), page_link);
            // 删除被分配出去的页
            list_del(list_next(&buddy.array[order]));
            // 别忘了重置属性，但不包括property，因为后面还要用到
            ClearPageProperty(ret);
            break;
        }
        else
        {
            // 这种情况就是该阶层已经没有空闲的块可以分配了
            // 此时需要不断循环到上一层继续查找
            size_t tmp = pageNumber;
            for (int i = order + 1; i <= buddy.max; i++)
            {
                if (!list_empty(&buddy.array[i]))
                {
                    // 此时相当于在上层找到了空闲的块
                    // 但是需要做二分块的操作,首先获取该块首页指针
                    list_entry_t *le = list_next(&(buddy.array[i]));
                    struct Page *left = le2page(le, page_link);
                    // tmp 是当前阶数对应的页数的一半，因此可以获得另一半的首页指针
                    struct Page *right = left + tmp;
                    // 维护新的阶数和属性
                    left->property = i - 1;
                    right->property = i - 1;
                    SetPageProperty(left);
                    SetPageProperty(right);

                    // 删除原来的大块，但是添加新的小块
                    list_del(le);
                    list_add(&(buddy.array[i - 1]), &(left->page_link));
                    list_add(&(left->page_link), &(right->page_link));

                    break;
                }
                if (i > buddy.max)
                {
                    // 防止数组越界
                    break;
                }
                tmp *= 2;
            }
        }
    }

    // 当分配成功时，别忘了要维护剩余的空闲块的数量
    if (ret != NULL)
    {
        buddy.free -= pageNumber;
    }
    return ret;
}
```

**第一**：我们要找到一个需要被正确分配的目标页数，这个数字是大于n的，最接近n的那个2的幂数。注意，correct_n函数找到的数一定是<=n的2幂数，因此再加上一个条件判断即可把目标页数求出来，为pageNumber。顺便把阶数也求出来，为order。

**第二**：直接进入一个死循环，直到找到要分配的那个块再break。也许这违背正常编程的直觉，要是找不到符合条件的块，岂不是要一直死循环吗？

请注意，在这之前，代码已经检查了，即分配的页数是一定<=当前内存中所剩的空闲页数的，此时就意味着一定能找到可以被分配的块。因为：

当存在一个块，其大小>=n时，可以直接分配。

当内存被切割的支离破碎，累计free的确大于n，但没有一个块大小>=n时，违背了分配算法的规则。因为分配算法总是优先分配每个阶层的第一个空闲的块：

```
list_del(list_next(&buddy.array[order]));
```

如下的情况是绝对不会发生的。

![image-20251018155344396](第二次实验.assets/image-20251018155344396.png)

算法会将第二个使用块实际分配到第一个空闲块处，因此一定是有4大小的块是可以分配的

**第三**：循环内，如果当前目标阶层是空的，就意味着需要依靠上层来“二分”出子块了。

二分算法是一个循环，要求要找到第一个能够二分的块，并且将其二分到下一层去。

这里讲一下二分地址该怎么计算，首先该块地址(简记为base)就是左孩子的地址，右孩子的地址则可以用base+该块包含的页数量的一半来计算。

然后break，继续外层循环，直到目标阶层不为空，找到了能够被分配的块，此时break跳出死循环。

**第四**：返回前别忘了维护新的free值，这等于减去pageNumber，最后返回ret。



#### ⑤释放函数

```c
static void
buddy_system_free_pages(struct Page *base, size_t n)
{
    // 输入的合法性检测
    assert(base != NULL && n > 0);
    // 直接用地址加入对应的阶层
    list_add(&(buddy.array[base->property]), &(base->page_link));
    SetPageProperty(base);
    // 现在需要回溯，合并地址相邻的空闲块
    // 首先获取此次释放的块的相邻块
    struct Page *buddy_block1 = base;
    struct Page *buddy_block2 = getBuddy(base,base->property);
    // 开始递归
    while(PageProperty(buddy_block2) && buddy_block1->property < buddy.max){
        // block1和block2，要先求出地址在前的那个块
        if(buddy_block1 > buddy_block2){
            // 说明block1地址在block2之后，进行交换
            struct Page *tmp = buddy_block1;
            buddy_block1 = buddy_block2;
            buddy_block2 = tmp;
            // 将在后面的那个块的阶数属性设置为-1，表示被合并你了
            buddy_block2->property = -1;
        }
        // 删除小块，添加大块
        list_del(&(buddy_block2->page_link));
        list_del(&(buddy_block1->page_link));
        buddy_block1->property++;
        list_add(&(buddy.array[buddy_block1->property]), &(buddy_block1->page_link));

        // 求出新的伙伴块
        buddy_block2 = getBuddy(buddy_block1,buddy_block1->property);
    }
    SetPageProperty(buddy_block1);
    // 操作完成后，不要忘记更新剩余空闲块的数量
    size_t pageNumber = correct_n(n);
    if (pageNumber != n)
    {
        pageNumber *= 2;
    }
    buddy.free += pageNumber;
    return ;
}
```

难点在于递归的回溯合并相邻的空闲块，这里辅助函数getBuddy用于寻找传入块的伙伴块。其代码为：
```c
static struct Page *
getBuddy(struct Page *base, unsigned int property)
{
    // 先计算该块包含了多少物理页
    unsigned int temp = 1;
    for(int i = 0; i < property; i++){
        temp = temp * 2;
    }
    size_t real_block_size = temp;

    //计算自己的相对偏移量 
    size_t relative_base = (size_t)base - 0xffffffffc020f318;
    //计算块的大小，0x28是一个page结构体的大小
    size_t sizeOfPage = real_block_size * 0x28;           
    size_t buddy_relative_addr = (size_t)relative_base ^ sizeOfPage;      //计算出字节偏移量
    struct Page *buddy = (struct Page *)(buddy_relative_addr + 0xffffffffc020f318); //计算伙伴块的真实地址
    return buddy;
}
```

首先需要知道一个规律，就是相邻的两个大小相同的块，他们的：

相对于内存起始地址的相对地址的异或 = 块的大小

因此伙伴块的虚拟地址 = 内存块起始地址 + 伙伴块的相对虚拟地址

= 内存块起始地址 +（自己的相对虚拟地址 ^ 块的大小）

在前面的实验中，我们发现内存的虚拟起始地址是0xffffffffc020f318，我们还知道

块的大小 = 物理页数 * 页结构大小(0x28)

知道这些之后，我们能够计算出最后的伙伴块的地址，并将其返回。



**（续，释放函数）**

递归需要使用一个while，而出口就是到达根节点，无法再合并，或者伙伴块不再空闲

假设block1表示刚被释放的块，block2表示一开始的伙伴块，那么我们要先求出谁在前谁在后，使用在前的那个block的地址表示合并后的大块的地址。别忘了每次循环的最后，都要根据新的大块，求出它的伙伴块，以进行下一次合并。

最后的最后，还是不要忘记更新剩余空闲块的数量。



#### ⑥ 补充一个打印函数

```c
static void
show_buddy_array(int left, int right)
{
    cprintf("------------------ Buddy System Free Lists ------------------\n");
    for (int i = left; i <= right; i++)
    {
        if (list_empty(&buddy.array[i]))
        {
            cprintf("Order %d: Empty\n", i);
        }
        else
        {
            cprintf("Order %d: ", i);
            list_entry_t *le = &buddy.array[i];
            while ((le = list_next(le)) != &buddy.array[i])
            {
                struct Page *page = le2page(le, page_link);
                cprintf("[%p, size=%d] ", page, 1 << page->property);
            }
            cprintf("\n");
        }
    }
    cprintf("Total free pages: %d\n", buddy.free);
    cprintf("-------------------------------------------------------------\n");
}
```

这个打印函数能帮我们了解每一层都包含了哪几个空闲块，他们的起始地址是多少，以便于之后的测试。



## 测试 buddy system

共分为五个模块，来对我们写的buddy system算法进行测试：

**①基本分配和释放  ②最小分配测试  ③最大分配测试  ④复杂分配释放  ⑤边界情况测试**

使用make grade命令，会在lab2目录中创建出一个.qemu.out文件，通过这个文件可以观察到调试的结果。

#### ①基本分配和释放

```c
// 基本分配和释放测试
static void
buddy_system_check_basic(void)
{
    cprintf("=== Basic Allocation and Free Test ===\n");
    cprintf("Initial free pages: %d\n", buddy.free);
    
    struct Page *p0, *p1, *p2;
    p0 = p1 = p2 = NULL;

    // 分配三个10页的块
    cprintf("Allocating 10 pages for p0...\n");
    p0 = buddy_system_alloc_pages(10);
    assert(p0 != NULL);
    show_buddy_array(0, MAX_ORDER);

    cprintf("Allocating 10 pages for p1...\n");
    p1 = buddy_system_alloc_pages(10);
    assert(p1 != NULL);
    show_buddy_array(0, MAX_ORDER);

    cprintf("Allocating 10 pages for p2...\n");
    p2 = buddy_system_alloc_pages(10);
    assert(p2 != NULL);
    show_buddy_array(0, MAX_ORDER);

    // 验证分配结果
    assert(p0 != p1 && p0 != p2 && p1 != p2);
    assert(page_ref(p0) == 0 && page_ref(p1) == 0 && page_ref(p2) == 0);
    assert(page2pa(p0) < npage * PGSIZE);
    assert(page2pa(p1) < npage * PGSIZE);
    assert(page2pa(p2) < npage * PGSIZE);

    cprintf("p0 address: 0x%016lx\n", p0);
    cprintf("p1 address: 0x%016lx\n", p1);
    cprintf("p2 address: 0x%016lx\n", p2);

    // 释放内存
    cprintf("Freeing p0...\n");
    buddy_system_free_pages(p0, 10);
    show_buddy_array(0, MAX_ORDER);

    cprintf("Freeing p1...\n");
    buddy_system_free_pages(p1, 10);
    show_buddy_array(0, MAX_ORDER);

    cprintf("Freeing p2...\n");
    buddy_system_free_pages(p2, 10);
    show_buddy_array(0, MAX_ORDER);

    cprintf("Basic test completed successfully!\n\n");
}
```

连续分配3个10页大小的块和连续释放他们。结果如下（讲解以注释呈现）：
```
=== Basic Allocation and Free Test ===
Initial free pages: 16384
Allocating 10 pages for p0...
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: [0xffffffffc020f598, size=16]     // 分配了一个16大小的块，还剩一个
Order 5: [0xffffffffc020f818, size=32] 	   // 下面每层同理
Order 6: [0xffffffffc020fd18, size=64] 
Order 7: [0xffffffffc0210718, size=128] 
Order 8: [0xffffffffc0211b18, size=256] 
Order 9: [0xffffffffc0214318, size=512] 
Order 10: [0xffffffffc0219318, size=1024] 
Order 11: [0xffffffffc0223318, size=2048] 
Order 12: [0xffffffffc0237318, size=4096] 
Order 13: [0xffffffffc025f318, size=8192] 
Order 14: Empty								// 根节点被“二分”了所以没有了
Total free pages: 16368						// 少了16
-------------------------------------------------------------
Allocating 10 pages for p1...
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: Empty								// 16大小的块被分完了
Order 5: [0xffffffffc020f818, size=32] 
Order 6: [0xffffffffc020fd18, size=64] 
Order 7: [0xffffffffc0210718, size=128] 
Order 8: [0xffffffffc0211b18, size=256] 
Order 9: [0xffffffffc0214318, size=512] 
Order 10: [0xffffffffc0219318, size=1024] 
Order 11: [0xffffffffc0223318, size=2048] 
Order 12: [0xffffffffc0237318, size=4096] 
Order 13: [0xffffffffc025f318, size=8192] 
Order 14: Empty
Total free pages: 16352						// 少了16
-------------------------------------------------------------
Allocating 10 pages for p2...
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: [0xffffffffc020fa98, size=16]		// 这里是第五层的块二分出了两个小
Order 5: Empty								// 块，其中一个被用于分配了，剩一
Order 6: [0xffffffffc020fd18, size=64] 		// 个，第五层变为空。
Order 7: [0xffffffffc0210718, size=128] 
Order 8: [0xffffffffc0211b18, size=256] 
Order 9: [0xffffffffc0214318, size=512] 
Order 10: [0xffffffffc0219318, size=1024] 
Order 11: [0xffffffffc0223318, size=2048] 
Order 12: [0xffffffffc0237318, size=4096] 
Order 13: [0xffffffffc025f318, size=8192] 
Order 14: Empty
Total free pages: 16336						// 少了16
-------------------------------------------------------------
p0 address: 0xffffffffc020f318				// 内存的起始地址，符合事实
p1 address: 0xffffffffc020f598				// 相差0x280，也就是16*0x28
p2 address: 0xffffffffc020f818				// 同理
Freeing p0...
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: [0xffffffffc020f318, size=16] [0xffffffffc020fa98, size=16] 
Order 5: Empty								// 一个16大小的块被释放回来了
Order 6: [0xffffffffc020fd18, size=64] 		// 但因为不是伙伴块，所以不合并
Order 7: [0xffffffffc0210718, size=128] 
Order 8: [0xffffffffc0211b18, size=256] 
Order 9: [0xffffffffc0214318, size=512] 
Order 10: [0xffffffffc0219318, size=1024] 
Order 11: [0xffffffffc0223318, size=2048] 
Order 12: [0xffffffffc0237318, size=4096] 
Order 13: [0xffffffffc025f318, size=8192] 
Order 14: Empty
Total free pages: 16352						// 加16
-------------------------------------------------------------
Freeing p1...
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: [0xffffffffc020fa98, size=16]       // 释放回来伙伴块，所以合并成了
Order 5: [0xffffffffc020f318, size=32] 		 // 一个32块，剩下一个16块
Order 6: [0xffffffffc020fd18, size=64] 
Order 7: [0xffffffffc0210718, size=128] 
Order 8: [0xffffffffc0211b18, size=256] 
Order 9: [0xffffffffc0214318, size=512] 
Order 10: [0xffffffffc0219318, size=1024] 
Order 11: [0xffffffffc0223318, size=2048] 
Order 12: [0xffffffffc0237318, size=4096] 
Order 13: [0xffffffffc025f318, size=8192] 
Order 14: Empty
Total free pages: 16368						// 加16
-------------------------------------------------------------
Freeing p2...
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: Empty
Order 5: Empty
Order 6: Empty
Order 7: Empty
Order 8: Empty
Order 9: Empty
Order 10: Empty
Order 11: Empty
Order 12: Empty
Order 13: Empty
Order 14: [0xffffffffc020f318, size=16384]	// 所有块被收回后，一路合并直到
Total free pages: 16384						// 只有根节点
-------------------------------------------------------------
Basic test completed successfully!
```



#### ②最小分配

```c
static void
buddy_system_check_min(void)
{
    cprintf("=== Minimum Allocation Test (1 page) ===\n");
    cprintf("Initial free pages: %d\n", buddy.free);
    
    struct Page *p = buddy_system_alloc_pages(1);
    assert(p != NULL);
    cprintf("Allocated 1 page at address: 0x%016lx\n", p);
    show_buddy_array(0, MAX_ORDER);
    
    buddy_system_free_pages(p, 1);
    cprintf("Freed 1 page\n");
    show_buddy_array(0, MAX_ORDER);
    
    cprintf("Minimum allocation test completed successfully!\n\n");
}
```

分配和释放一个大小为1的块，以下是测试结果：

```
=== Minimum Allocation Test (1 page) ===
Initial free pages: 16384
Allocated 1 page at address: 0xffffffffc020f318
------------------ Buddy System Free Lists ------------------
Order 0: [0xffffffffc020f340, size=1] 		// 一路二分到底分配出一个阶层
Order 1: [0xffffffffc020f368, size=2] 		// 数为0的块
Order 2: [0xffffffffc020f3b8, size=4] 
Order 3: [0xffffffffc020f458, size=8] 
Order 4: [0xffffffffc020f598, size=16] 
Order 5: [0xffffffffc020f818, size=32] 
Order 6: [0xffffffffc020fd18, size=64] 
Order 7: [0xffffffffc0210718, size=128] 
Order 8: [0xffffffffc0211b18, size=256] 
Order 9: [0xffffffffc0214318, size=512] 
Order 10: [0xffffffffc0219318, size=1024] 
Order 11: [0xffffffffc0223318, size=2048] 
Order 12: [0xffffffffc0237318, size=4096] 
Order 13: [0xffffffffc025f318, size=8192] 
Order 14: Empty
Total free pages: 16383
-------------------------------------------------------------
Freed 1 page
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: Empty
Order 5: Empty
Order 6: Empty
Order 7: Empty
Order 8: Empty
Order 9: Empty
Order 10: Empty
Order 11: Empty
Order 12: Empty
Order 13: Empty
Order 14: [0xffffffffc020f318, size=16384] 		// 然后又一路回归了
Total free pages: 16384
-------------------------------------------------------------
Minimum allocation test completed successfully!
```



#### ③最大分配测试

```c
static void
buddy_system_check_max(void)
{
    cprintf("=== Maximum Allocation Test (16384 pages) ===\n");
    cprintf("Initial free pages: %d\n", buddy.free);
    
    struct Page *p = buddy_system_alloc_pages(16384);
    if (p == NULL) {
        cprintf("Warning: Cannot allocate 16384 pages (might be expected)\n");
        return;
    }
    
    cprintf("Allocated 16384 pages at address: 0x%016lx\n", p);
    show_buddy_array(0, MAX_ORDER);
    
    buddy_system_free_pages(p, 16384);
    cprintf("Freed 16384 pages\n");
    show_buddy_array(0, MAX_ORDER);
    
    cprintf("Maximum allocation test completed successfully!\n\n");
}
```

也就是直接分配走最大的那个块（大小16384！），然后再释放，以下是测试结果：

```
=== Maximum Allocation Test (16384 pages) ===
Initial free pages: 16384
Allocated 16384 pages at address: 0xffffffffc020f318
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: Empty
Order 5: Empty
Order 6: Empty
Order 7: Empty
Order 8: Empty
Order 9: Empty
Order 10: Empty
Order 11: Empty
Order 12: Empty
Order 13: Empty
Order 14: Empty				// 全空，并且free pages也归零了
Total free pages: 0
-------------------------------------------------------------
Freed 16384 pages
------------------ Buddy System Free Lists ------------------
Order 0: Empty
Order 1: Empty
Order 2: Empty
Order 3: Empty
Order 4: Empty
Order 5: Empty
Order 6: Empty
Order 7: Empty
Order 8: Empty
Order 9: Empty
Order 10: Empty
Order 11: Empty
Order 12: Empty
Order 13: Empty
Order 14: [0xffffffffc020f318, size=16384] 		// 释放之后，根节点又回来了
Total free pages: 16384
-------------------------------------------------------------
Maximum allocation test completed successfully!
```



#### ④复杂分配释放测试

也就是针对分配和释放，测试一些数字不同情况不同的测试样例，由于篇幅有限，就不展示测试函数和最终的测试结果了，但相关函数存放在buddy_system_pmm.c中，测试结果在.qemu.out中，都是可以查看的到的



#### ⑤边界情况测试

```c
static void
buddy_system_check_edge_cases(void)
{
    cprintf("=== Edge Cases Test ===\n");
    cprintf("Initial free pages: %d\n", buddy.free);
    
    // 测试分配0页（应该失败）
    cprintf("Testing allocation of 0 pages...\n");
    struct Page *p0 = buddy_system_alloc_pages(0);
    assert(p0 == NULL);
    cprintf("Allocation of 0 pages correctly failed\n");
    
    // 测试分配超过最大可用页数
    cprintf("Testing allocation beyond available pages...\n");
    size_t too_many = buddy.free + 1;
    struct Page *p1 = buddy_system_alloc_pages(too_many);
    assert(p1 == NULL);
    cprintf("Allocation of %d pages correctly failed\n", too_many);
    
    cprintf("Edge cases test completed successfully!\n\n");
}
```

简单的测试一下算法对一些边界数据的处理能力（例如n=0或超过分配上限），测试结果如下：

```
=== Edge Cases Test ===
Initial free pages: 16384
Testing allocation of 0 pages...
Allocation of 0 pages correctly failed
Testing allocation beyond available pages...
Allocation of 16385 pages correctly failed
Edge cases test completed successfully!

Final free pages: 16384
Initial free pages: 16384
============================================
All Buddy System Tests Completed Successfully!
```



最后给出对外的接口以供调用：

```c
const struct pmm_manager buddy_system_pmm_manager = {
    .name = "buddy_system_pmm_manager",
    .init = buddy_system_init,
    .init_memmap = buddy_system_init_memmap,
    .alloc_pages = buddy_system_alloc_pages,
    .free_pages = buddy_system_free_pages,
    .nr_free_pages = buddy_system_nr_free_pages,
    .check = buddy_system_check,
};
```

通过ucore测试的结果图如下：

![image-20251018170431878](第二次实验.assets/image-20251018170431878-1760778276064-2.png)



**至此，buddy system的实现和测试完毕！**



### 扩展练习Challenge：任意大小的内存单元slub分配算法（需要编程）
slub算法，实现两层架构的高效内存单元分配，第一层是基于页大小的内存分配，第二层是在第一层基础上实现基于任意大小的内存分配。可简化实现，能够体现其主体思想即可。

参考linux的slub分配算法/，在ucore中实现slub分配算法。要求有比较充分的测试用例说明实现的正确性，需要有设计文档。

### 扩展练习Challenge：硬件的可用物理内存范围的获取方法（思考题）
如果 OS 无法提前知道当前硬件的可用物理内存范围，请问你有何办法让 OS 获取可用物理内存范围？


OS 在启动阶段需要知道哪些物理地址可以使用,哪些是保留区域（比如设备寄存器、ROM、内核本身）,哪些是不可访问或未映射的空间等等。但如果OS启动时无法提前知道可用物理内存范围，那 OS 就必须通过某种机制来动态获取这些信息。

常见的几种获取物理内存范围的方式有：

#### 1.固件/引导程序传递，通过设备树 (DTB)传递内存布局

几乎所有现代 RISC-V 平台都通过 Device Tree Blob (DTB) 传递硬件拓扑信息。Bootloader（如 OpenSBI 或 U-Boot）会将 DTB 的物理地址传给 OS，OS 启动时解析 /memory 节点，即可获得所有可用物理内存段。本次实验我们就用了这个办法。

如下图，在本次实验中，我们把DTB的地址保存在了a0寄存器里边.

<p align="center">
  <img src="figure/zdm_figure1.png" alt="figure">
</p>

然后在dtb.c文件的dtb_init函数里对dtb进行解析，获取内存可用物理地址的首地址及其大小。它们被读取到了全局变量memory_base和memory_size中，后续在物理内存管理初始化的时候用到这些信息。

<p align="center">
  <img src="figure/zdm_figure2.png" alt="figure">
</p>

如下图，在make qemu运行代码以后，我们可以看见以下的调试信息，可用内存地址由0x80000000开始，大小是0x08000000。

<p align="center">
  <img src="figure/zdm_figure3.png" alt="figure">
</p>

#### 2.固件调用接口,RISC-V可以通过OpenSBI扩展接口查询

要用SBI查询内存信息，通常需要两条路径之一：

1.由 bootloader把 DTB 传给内核，内核解析 DTB（也就是我们的方法1）

2.实现一个SBI扩展，内核通过ecall向OpenSBI请求内存信息。SBI标准本身提供了许多扩展（hart 管理、IPI、时间、console、固件管理等），但没有被广泛接受的、固定的通用内存信息系统调用标准，所以需要用户自己实现一个OpenSBI扩展。

#### 3.内存探测（试探法）

在早期裸机实验或无固件的最小RISC-V SoC中，有时可能会通过探测法来猜内存：即从假设的起始地址开始，每隔一段写入测试值再读回，试探法的核心思想是：从某个起始物理地址按步长访问（读/写/读回），通过判断读取结果是否正确或CPU是否发生访问故障来判断该地址是否真正映射到DRAM可用内存）。

例如，下图代码实现了从0x80000000开始，以页为单位，尝试向当前地址写入0xdeadbeef，从而探测可用物理内存：

    uintptr_t addr = 0x80000000; 
    while (addr < MAX_ADDR) { 
        volatile uint64_t *p = (uint64_t *)addr; 
        uint64_t old = *p; 
        *p = 0xdeadbeef; 
        if (*p != 0xdeadbeef) break; // 读写失败 
        *p = old; 
        addr += PAGE_SIZE; }

一般我们默认设置DRAM base = 0x80000000，以页为单位一页一页去测试。

但是这个方法有很大的缺点：

1.写入测试值可能破坏 MMIO 寄存器或外设状态。入测试值可能破坏 MMIO 寄存器或外设状态。MMIO是把硬件寄存器映射到CPU地址空间，让CPU通过普通内存访问控制硬件。MMIO 写操作可能改变设备状态，甚至造成系统不可预测行为，破坏硬件设备。

2.不一定能区分 RAM 与 MMIO。有些MMIO寄存器也可写且读回值可控，看起来像 RAM，有些可能返回固定值或状态字，这样会误判，把MMIO当作RAM。

3.性能低。逐页扫描非常慢，如果内存很大，耗时明显。

#### 4.硬件寄存器查询（SoC 特定）
在很多 SoC（System on Chip）或者嵌入式平台上，DRAM 的大小、起始地址、类型等信息并不是固定的，而是由 内存控制器管理。内存控制器通常集成在 SoC 内部。它负责初始化 DRAM，记录 DRAM 地址范围和配置参数。

内存控制器在启动时会有一些寄存器保存DRAM起始物理地址，DRAM大小，内存类型等等，为了让操作系统知道可用内存，需要读取内存控制器的寄存器。内存控制器寄存器通常映射在SoC的固定物理地址空间。


## 列出你认为本实验中重要的知识点，以及与对应的OS原理中的知识点，并简要说明你对二者的含义，关系，差异等方面的理解（也可能出现实验中的知识点没有对应的原理知识点）

### 动态分区分配算法
#### os理论知识
动态分区分配算法也可以称为可变分区分配，是指在进程装入内存时，根据进程的实际需要，动态的为之分配内存，使分区的大小刚好适合进程的需要。动态分区分配算法可以大致分为两类，基于顺序的动态分配算法和基于索引的动态分配算法。

##### 基于顺序的动态分配算法

顺序分配算法的核心思想是内核维护一个空闲内存块链表，记录每块空闲内存的起始地址和大小。当有内存请求时，按链表顺序查找合适的块分配。内存释放后，将块重新插入链表，并尝试与相邻空闲块合并。

顺序分配算法常见策略有四种：

1.First Fit

空闲分区按照地址大小递增排列，分配时从链表头开始遍历，找到第一个大小满足请求的块，分配该块，剩余部分作为新的空闲块。它查找速度快，实现简单，但链表头容易产生碎片，长期使用可能导致效率下降。

2.Best Fit
空闲分区按照内存大小递增排列，分配时遍历链表，找到最接近请求大小的块分配。其优点是最大程度减少浪费，但是查找慢，容易产生很多小碎片。

3.Worst Fit

空闲分区按照内存大小递减排列，分配时遍历链表找最大的空闲块分配，可以保留较大空闲块以备后续大请求，同时避免产生碎片，但是容易没有大内存可以用。

4.Next Fit

类似First Fit，但每次查找从上一次分配位置开始，遍历到链表尾后回到头部，优点是平均分配速度均衡，避免链表头过度碎片化，但缺点是对于减少小碎片没有明显优势，仍需遍历链表

##### 基于索引的动态分配算法

索引分配算法的核心思想是通过索引或分组快速找到合适空闲块，减少遍历时间。适用于内存请求大小多样或系统内存较大的场景。

常见方法包括 Quick Fit、Buddy System、哈希分配。

1.Quick Fit（快速适应）

这个方法维护多个链表，每个链表存放固定大小的空闲块，分配请求时，匹配链表大小满足的最小的空闲分区链表，直接分配第一块。优点是分配速度非常快，对常用大小块高效。但是维护多个链表增加复杂性。

2.Buddy System（伙伴系统）

把内存按 2 的幂划分（1KB, 2KB, 4KB, …），当需要一个2^i大小的块时，如果有，就分配，如果没有，就找2^(i+1)大小的块，如果存在，将其划分为两个2^i大小的块，一个分配，另一个接入链表。回收时如果伙伴块空闲，则合并成更大块。

3.Hash-based Allocation（哈希分配）

将空闲块按大小映射到哈希表，分配时直接通过哈希快速查找。

#### 实验知识点
在本次os实验中涉及到了两种动态分区分配算法，即first-fit算法和best-fit算法，在挑战题目里涉及到了伙伴系统分配算法，这三种算法都是动态分区分配算法，区别在于前两种是基于顺序搜索的，即依次遍历链表上的空闲区块，而伙伴系统分配算法是基于索引分配的。

具体理论知识在上边都说过了，此处主要讲一些代码的实际编程知识和理论知识的一些区别。首先我们知道，Best Fit算法规定空闲分区按照内存大小递增排列，分配时遍历链表，找到最接近请求大小的块分配。那么在具体实施的时候，实际上就有两种策略。

第一种，仍然按照地址大小排列，但是在寻找要分配的区块的时候把整个链表都找一遍，然后找到满足条件的最小的区别进行分配，合并算法了类似于first-fit,因为它是按照地址大小排列的。

第二种，就是按照内存大小进行排列，这样找的时候第一个满足条件的就是最小的，在合并的时候，类似于first-fit，去扫一遍那个链表，去找所有地址小于或大于这个块的，尝试合并，合并以后再扫一遍，进行插入。

### 分页存储机制


#### os知识点

分页存储机制是一种将内存管理按固定大小划分的技术，它把虚拟内存划分为页，物理内存划分为页框，每个页的大小通常为4KB或8KB。

每个进程拥有独立的虚拟地址空间，CPU访问内存时首先生成虚拟地址，虚拟地址被拆分为虚拟页号（VPN）和页内偏移（Offset），页号用于查页表以找到对应的物理页框，偏移用于定位页内具体字节。

页表项除了记录物理页框号外，还包含有效位、读写执行权限位、用户/内核模式位以及访问和脏位等信息，这些标志位帮助操作系统实现内存保护、按需分配和页面置换策略。

由于单级页表在大地址空间下会非常庞大，现代操作系统通常采用多级页表来节省内存并支持大地址空间。例如在RISC-V Sv39架构下，虚拟地址是39位，页大小为4KB，虚拟地址被拆分为三级索引加页内偏移：高9位用于顶级页表（L1），中间9位用于二级页表（L2），低9位用于三级页表（L3），最后12位为页内偏移（4kB）。CPU访问虚拟地址时，首先用顶级页表索引查找L1页表，找到L2页表物理地址，再用中间索引查找L2页表，得到L3页表物理地址，最终用低位索引在L3页表找到目标物理页框号，并加上页内偏移生成最终物理地址。多级页表只有在对应虚拟页实际使用时才分配，从而节省大量内存。

为了提高访问效率，系统中还使用了快表TLB。

TLB是CPU内部或旁路高速缓存，存储最近使用的虚拟页号到物理页框号的映射。每次CPU访问虚拟地址时，会先查询TLB，如果命中直接生成物理地址，无需访问多级页表，从而减少延迟。如果TLB未命中，则CPU按多级页表顺序查找页表，并将查到的映射写入TLB以供后续使用。当操作系统进行页面置换或修改页表时，需要刷新TLB以保持缓存的一致性。

分页机制还支持内存保护、共享内存和按需分配。通过页表项中的权限位，操作系统可以阻止用户态程序访问内核空间，或者禁止某些页被写入，从而保证安全性。同时，操作系统可以在需要时才分配物理页框，未使用的虚拟页可以不映射物理内存，这样实现按需分配和延迟分配。

satp 寄存器在RISC-V架构下用于管理页表基址。
#### 实验知识点

在本次实验代码里也实现了分页机制：

        t0 := 三级页表的虚拟地址
        lui     t0, %hi(boot_page_table_sv39)
        # t1 := 0xffffffff40000000 即虚实映射偏移量
        li      t1, 0xffffffffc0000000 - 0x80000000
        # t0 减去虚实映射偏移量 0xffffffff40000000，变为三级页表的物理地址
        sub     t0, t0, t1
        # t0 >>= 12，变为三级页表的物理页号
        srli    t0, t0, 12
    
        # t1 := 8 << 60，设置 satp 的 MODE 字段为 Sv39
        li      t1, 8 << 60
        # 将刚才计算出的预设三级页表物理页号附加到 satp 中
        or      t0, t0, t1
        # 将算出的 t0(即新的MODE|页表基址物理页号) 覆盖到 satp 中
        csrw    satp, t0
        # 使用 sfence.vma 指令刷新 TLB
        sfence.vma
以及

    .section .data
        # 由于我们要把这个页表放到一个页里面，因此必须 12 位对齐
        .align PGSHIFT
        .global boot_page_table_sv39
    # 分配 4KiB 内存给预设的三级页表
    boot_page_table_sv39:
        # 0xffffffff_c0000000 map to 0x80000000 (1G)
        # 前 511 个页表项均设置为 0 ，因此 V=0 ，意味着是空的(unmapped)
        .zero 8 * 511
        # 设置最后一个页表项，PPN=0x80000，标志位 VRWXAD 均为 1
        .quad (0x80000 << 10) | 0xcf # VRWXAD


​    
这段代码的功能是为内核建立一个Sv39三级页表映射，它首先计算页表的物理页号(减法)，并与Sv39模式标志组合写入 `satp` 寄存器，然后通过 `sfence.vma` 刷新页表缓存，从此内核的所有内存操作都在虚拟地址下进行，不再直接依赖物理地址。

这段代码的作用是在内核数据段中分配一个4KB的页表页，并初始化Sv39三级页表：前 511 个条目置为 0，表示这些虚拟页号未映射，最后一个条目设置物理页号PPN=0x80000，同时将标志位VRWXAD 全部置为 1，表示这一条页表项是叶子，从而实现将虚拟地址 0xffffffffc0000000 映射到物理地址 0x80000000的1GB超大页映射。

可以注意到，这里有一些新的知识，也就是三级页表我们不一定全部用完。

根据实验指导书的介绍，Sv39页表的根节点会占据一页4KiB的内存，存储512个页表项（一个页表项占据8字节），分别对应512个1GiB的大大页。虚拟地址27位页号中的高9位用来在根节点中索引页表项，找到对应的大大页（注意只有合法的页表项才是根节点的儿子，可以跳转到一个物理页号，对应树中一个“大大页”的节点）。

大大页同样是4KiB的内存存储512个页表项，对应512个2MiB的大页，虚拟地址27位页号中的中9位用来在大大页中索引页表项，找到对应的大页的物理页号（同样需要是合法的）。同理，大页的配置与根节点、大大页如出一辙，通过虚拟地址27位页号中的低9位索引大页，便可以找到虚拟地址对应的4KiB物理页，接着用12位页内偏移索引物理页来找到具体的内容。

三级和二级页表项不一定要指向下一级页表。我们知道每个一级页表项控制一个虚拟页号，即控制 4KiB 虚拟内存；每个二级页表项则控制 9 位虚拟页号，总计控制 4KiB×2^9 =2MiB 虚拟内存；每个三级页表项控制 18 位虚拟页号，总计控制 2MiB×2^9 =1GiB 虚拟内存。我们可以将二级页表项的 R,W,X 设置为不是全 0 的许可要求，那么它将与一级页表项类似，只不过可以映射一个 2MiB 的大页 (Mega Page) 。同理，也可以将三级页表项看作一个叶子，来映射一个 1GiB 的大大页(Giga Page)。


## 列出你认为OS原理中很重要，但在实验中没有对应上的知识点

### 程序的装入

之前我们一直在讲怎么给程序分配内存，但是我认为有必要了解一下程序是怎么装入内存的。装入是操作系统或引导程序将可执行文件映射到内存并准备执行的过程。对于裸机内核来说，引导程序（Bootloader）会把ELF文件解析，将.text段加载到内存的执行区，把.data段加载到内存数据区，并将.bss段清零。装入过程中还会处理符号重定位，确保指令中引用的地址是正确的物理或虚拟地址。在现代操作系统中，装入器还可能建立页表，设置虚拟地址映射，从而让程序可以在虚拟内存空间运行。

程序装入的方法主要有三种经典方式：`绝对装入` 、`重定位装入`和`动态装入`。详细解释如下：

绝对装入是最简单的一种方法，编译和链接时已经把程序段的虚拟地址或物理地址固定好。装入器直接将程序的各段按照链接器指定的地址拷贝到内存即可，不需要做地址修改。优点是实现简单、开销低；缺点是程序不能灵活加载到不同内存位置，也不利于共享代码段或实现虚拟内存机制。只适用于单道程序环境。

重定位装入则允许程序在内存中任意位置加载。编译和链接生成的可执行文件包含了重定位信息，装入器在将程序段拷贝到内存时，根据装入地址调整程序中符号的地址引用。例如某条指令要访问全局变量，装入器会把原本的固定地址修改为实际装入的内存地址。重定位装入的优点是灵活性高，可以在不同内存区域运行同一程序副本，也便于操作系统管理内存和实现共享库；缺点是装入时需要额外的地址计算和修改开销。

动态装入是现代操作系统广泛使用的方法，程序的代码段和数据段不需要一次性全部装入内存，而是在程序访问某页时由操作系统通过缺页异常加载对应页到内存。可执行文件和共享库仍然保留在磁盘上，操作系统通过页表和虚拟内存机制动态映射页面。动态装入的优点是节省内存空间、加快启动速度，同时可以实现程序和库的共享；缺点是第一次访问某页时会产生缺页异常开销，设计复杂。

### 链接方式
根据链接时间不同，程序也有三种不同的链接方式。`静态链接`、`装入时链接`和`动态链接`。

静态链接
静态链接是链接器在程序运行前就把所有目标文件和静态库链接，修改相对地址，并生成完整的可执行文件。

装入时链接
装入时链接是在程序被装入内存的时候边装入边链接。

动态链接
动态链接是在程序运行时需要某个模块的时候才去链接它。现代操作系统用户程序和共享库多采用这种方式，可以节省内存和磁盘空间，同时方便更新库文件而无需重新编译程序。缺点是首次调用未解析的函数时会产生额外开销，设计和实现复杂。

### 基本分段存储管理

我们在实验中详细了解了分页内存管理，但是却没有详细介绍分段内存管理,这也是很常用很重要的内存管理方式。分段存储管理是一种以程序的逻辑区域（代码段、数据段、堆、栈等）为单位来管理内存的方式。每个逻辑区域被视为一个可变长度的段，操作系统和硬件维护一张段表来记录每个段在物理内存中的起始地址和界限并用段号或段选择子在运行时做地址转换与保护。

分段的主要优势在于它契合程序的逻辑结构：编译器和程序天然以段为单位（例如把代码放在只读的代码段，把全局数据放在data段，把堆和栈当作独立段），这样便于实现按段保护（只读代码、只写数据）、按段共享（多个进程可以把同一个共享库段映射到各自地址空间）和段级的增长（动态扩展堆或栈只需调整该段的 limit 或 base）。分段还便于动态重定位：如果段的 base 由 loader 在装入时设定，则同一段可以放入不同的物理位置而不需修改段内地址（只需在段表中写入不同的 base），这样减轻了装入时重定位的压力。

但分段也有明显缺点，那就是产生外部碎片。

段是可变长的连续物理区块，频繁分配和释放会在物理内存中产生许多不连续小空洞，最终可能需要内存压缩来合并空闲区；第二个问题是硬件与管理复杂性，CPU 必须支持段寄存器、段界限检查和相应异常，OS 必须维护段表并在进程切换时保存/加载；第三个问题是细粒度共享和内存利用率在多进程环境下往往不如页式管理（paging）。因此在现代通用操作系统中，单纯分段管理被逐步页式管理补充或替代，常见做法是“段+页”的混合方案：先以段实现逻辑隔离与重定位，再把段内部按页划分由页表管理（即段提供基址/界限、页提供内存分配与换入换出）。

历史上 x86 提供了相当复杂的分段机制（段选择子、段描述符表、可扩展的属性位、段限长单位等），但现代 x86-64 多数操作系统将段功能简化为基址为 0、界限为最大值以依赖页式管理实现隔离。分段仍在某些嵌入式或特殊用途系统中有用，例如实现进程间共享、动态重定位或对大对象做粗粒度保护。总体来说，分段适用于按逻辑单位组织内存和实现按段权限，而页式管理则在内存利用率、碎片控制和换页管理上更优，现实系统通常将两者结合以取长补短。

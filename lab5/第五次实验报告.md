<h1 align="center"> lab3：断,都可以断 </h1>

 <div align="center">

张德民 刘越帅 欧广元

</div>

## 实验目的

1. 了解第一个用户进程创建过程
2. 了解系统调用框架的实现机制
3. 了解ucore如何实现系统调用sys_fork/sys_exec/sys_exit/sys_wait来进行进程管理

## 实验内容
实验4完成了内核线程，但到目前为止，所有的运行都在内核态执行。实验5将创建用户进程，让用户进程在用户态执行，且在需要ucore支持时，可通过系统调用来让ucore提供服务。为此需要构造出第一个用户进程，并通过系统调用sys_fork/sys_exec/sys_exit/sys_wait来支持运行不同的应用程序，完成对用户进程的执行过程的基本管理。

## 实验过程

### 练习0 填写已有实验

本实验依赖实验2/3/4。请把你做的实验2/3/4的代码填入本实验中代码中有“LAB2”/“LAB3”/“LAB4”的注释相应部分。注意：为了能够正确执行lab5的测试应用程序，可能需对已完成的实验2/3/4的代码进行进一步改进。

### 练习1: 加载应用程序并执行（需要编码）

do_execv函数调用load_icode（位于kern/process/proc.c中）来加载并解析一个处于内存中的ELF执行文件格式的应用程序。你需要补充load_icode的第6步，建立相应的用户内存空间来放置应用程序的代码段、数据段等，且要设置好proc_struct结构中的成员变量trapframe中的内容，确保在执行此进程后，能够从应用程序设定的起始执行地址开始执行。需设置正确的trapframe内容。

#### 请在实验报告中简要说明你的设计实现过程。

    /* 将用户栈指针设置为用户栈顶（USTACKTOP） */
        tf->gpr.sp = USTACKTOP;

        /* 从 ELF 头获取程序入口地址并设置 sepc/epc */
        tf->epc = elf->e_entry;

        /* 构造返回到用户态时的 sstatus：
        * - 清除 SPP，使 sret 返回到用户态（U-mode）；
        * - 置位 SPIE，使 sret 后中断按 SPIE 的值恢复；
        * - 清除 SIE（在内核中禁用中断，等待 sret 由 SPIE 恢复）；
        * 同时尽量保留原有 sstatus 的其它位（如 SUM），以免破坏访问策略。
        */
        uintptr_t newsstatus = (sstatus & ~SSTATUS_SPP) | SSTATUS_SPIE;
        newsstatus &= ~SSTATUS_SIE;
        tf->status = newsstatus;

如上边的代码，就是我补充的第六步，主要是按照注释进行编写代码。

首先tf->gpr.sp是用户栈指针，应该设置为用户栈顶 所以设置为USTACKTOP，tf->epc是程序入口地址，所以设置为 ELF 头中的 e_entry。

tf->status是进程状态寄存器sstatus，应该设置为适合用户程序运行的值，首先拿用户态原本的 sstatus，然后把SSTATUS_SPP置零，说明这个进程应该去往用户态运行，以后执行sret时，返回到用户态。

然后把SSTATUS_SPIE置1，sret后用户态恢复“中断开启”。

最后SSTATUS_SIE置为0，表明在内核态不希望发生中断。

#### 请简要描述这个用户态进程被ucore选择占用CPU执行（RUNNING态）到具体执行应用程序第一条指令的整个经过。

kern_init 执行完 proc_init 后，会调用 cpu_idle()。在 cpu_idle() 中，有一个 while (1) 循环，由于 idleproc->need_resched = 1，循环会立即调用 schedule()。schedule() 会从就绪队列中选择下一个进程（也就是我们的用户进程user_main），然后通过 proc_run() 切换到它。此时，current变为user_proc，开始执行user_main函数。

在proc_run()中，首先禁用中断，保存当前进程指针，然后切换页表，切换上下文，最后打开中断，但是切换完成后，CPU在新进程的上下文中执行，但仍在内核态。

新进程恢复后，从forkret函数开始执行（这是switch_to恢复的返回地址，由copy_thread设置）。

forkret 调用 forkrets(current->tf)。

    .globl forkrets
    forkrets:
        # set stack to this new process's trapframe
        move sp, a0
        j __trapret


这是一个汇编函数，将栈指针sp设置为当前进程的 trapframe 地址（move sp, a0），然后跳转到 __trapret。

    .globl __trapret
    __trapret:
        RESTORE_ALL
        # return from supervisor call
        sret
 

__trapret 调用 RESTORE_ALL 宏，从 trapframe 中恢复所有寄存器，包括通用寄存器 (x0-x31)、状态寄存器 (sstatus)、异常程序计数器 (sepc/epc) 等。

user_main函数中，先声明链接时嵌入的用户程序二进制数据的起始地址和大小，然后调用kernel_execve函数，kernel_execve函数参数里a0存系统调用号，a1到a5是参数。然后调用一个ebreak中断，进入中断处理机制。然后保存当前的陷阱帧，调用sys_exec，sys_exec调用 do_execve，执行程序替换，清除旧内存，调用 load_icode 加载用户程序并设置新的用户trapframe等(也就是设置用户栈，epc设置为用户程序开始的地方，更新status寄存器等等)。

然后执行__trapret，先调用RESTORE_ALL宏，从新的用户trapframe恢复所有寄存器（包括 sepc、sstatus 等）。然后执行sret指令，sret 根据 sepc 设置 PC，并根据 sstatus 切换特权级别，返回到第一条用户指令去执行。

### 练习2: 父进程复制自己的内存空间给子进程（需要编码）

创建子进程的函数do_fork在执行中将拷贝当前进程（即父进程）的用户内存地址空间中的合法内容到新进程中（子进程），完成内存资源的复制。具体是通过copy_range函数（位于kern/mm/pmm.c中）实现的，请补充copy_range的实现，确保能够正确执行。

#### 请在实验报告中简要说明你的设计实现过程。

我实现的代码如下：


            /* (1) 找到 src_kvaddr：页（page）对应的内核虚拟地址
            * (2) 找到 dst_kvaddr：新页（npage）对应的内核虚拟地址
            * (3) 将 src_kvaddr 指向的内存内容拷贝到 dst_kvaddr，拷贝长度为 PGSIZE（页大小）
            * (4) 建立新页（npage）的物理地址与起始线性地址（start）之间的映射关系
             */
              /* (1) 源页面的内核虚拟地址 */
            void *src_kvaddr = page2kva(page);
            /* (2) 目标页面的内核虚拟地址 */
            void *dst_kvaddr = page2kva(npage);

            /* (3) 拷贝整页内容 */
            memcpy(dst_kvaddr, src_kvaddr, PGSIZE);

            /* (4) 在目标页表中建立映射，权限与源页相同 */
            ret = page_insert(to, npage, start, perm);
            if (ret != 0)
            {
                /* 建立映射失败，释放分配的页 */
                free_page(npage);
                return -E_NO_MEM;
            }
            /* 记录该页的虚拟地址映射信息（与 pgdir_alloc_page 一致） */
            npage->pra_vaddr = start;

首先，使用page2kva函数，找到父进程的页的对应内核虚拟地址，然后再用page2kva得到要为子进程分配的页的内核虚拟地址，然后把父进程的数据直接全部拷贝到子进程的页里。最后，在子进程的页目录里建立虚拟地址 start 到物理页面 npage 的映射，并记录这个页的虚拟地址信息。

#### 如何设计实现Copy on Write机制？给出概要设计，鼓励给出详细设计。

    Copy-on-write（简称COW）的基本概念是指如果有多个使用者对一个资源A（比如内存块）进行读操作，则每个使用者只需获得一个指向同一个资源A的指针，就可以该资源了。若某使用者需要对这个资源A进行写操作，系统会对该资源进行拷贝操作，从而使得该“写操作”使用者获得一个该资源A的“私有”拷贝—资源B，可对资源B进行写操作。该“写操作”使用者对资源B的改变对于其他的使用者而言是不可见的，因为其他使用者看到的还是资源A。

##### 概要设计

1. 核心原理：
   - 共享阶段：在fork时，父子进程共享父进程的物理页面，不复制内容。页面映射为只读（去掉写权限PTE_W），防止写操作破坏共享。
   - 写时复制：当某个进程尝试写共享页面时，触发page fault。内核检测到是COW页面（只读但原页面可写），复制页面内容到新物理页面，更新映射为可写。
   - 隔离保证：写操作后，每个进程拥有私有拷贝，修改不可见。

2. 关键组件：
   - 页面管理：利用`Page`结构体的`ref`字段（引用计数）跟踪共享页面。当`ref > 1`时，表示页面被共享。
   - 权限控制：在页表项(PTE)中设置只读权限（去掉PTE_W）。
   - 异常处理：扩展trap处理（`kern/trap/trap.c`），在page fault时检查是否为COW写操作。
   - 内存一致性：确保复制时不影响其他进程。


##### 详细设计

1. **修改copy_range函数（kern/mm/pmm.c）**：
   - 当前实现是直接复制：分配新页面`npage`，`memcpy`内容，然后`page_insert`。
   - **COW版本**：改为共享父进程页面，不复制内容。
     - 获取父进程页面`page`后，不分配`npage`，而是直接使用`page`。
     - 设置权限为只读：`perm &= ~PTE_W;`（去掉写权限）。
     - `page_insert(to, page, start, perm);` 将父页面映射到子进程页表（只读）。
     - 增加引用计数：`page_ref_inc(page);`。
     - 移除`memcpy`和`npage`分配逻辑。

   - **代码片段**（替换现有的LAB5:EXERCISE2部分）：
     ```c
     if (*ptep & PTE_V) {
         uint32_t perm = (*ptep & PTE_USER);
         struct Page *page = pte2page(*ptep);
         // COW: 设置为只读权限，共享页面
         perm &= ~PTE_W;
         int ret = page_insert(to, page, start, perm);
         if (ret != 0) {
             return -E_NO_MEM;
         }
         // 增加引用计数，表示共享
         page_ref_inc(page);

     }
     ```
   - **注意**：`npage->pra_vaddr = start;` 可移除，因为共享页面时虚拟地址由各进程页表决定。

2. 扩展Page Fault处理（kern/trap/trap.c）：

   - 添加COW逻辑：在`trap_dispatch`中，检测page fault（异常码为load/store page fault）。
     - 检查fault地址对应的PTE：如果页面只读（无PTE_W）且ref > 1，则触发COW复制。
     - **复制步骤**：
       - 分配新页面`npage`。
       - `memcpy`原页面内容到`npage`。
       - 更新当前进程的页表：`page_insert`新页面为可写（perm | PTE_W）。
       - 减少原页面的ref：`page_ref_dec(page);` 如果ref==0，释放页面。

     - **代码片段**（在trap_dispatch中添加）：
       ```c
       case CAUSE_LOAD_PAGE_FAULT:  // 或STORE_PAGE_FAULT，根据RISC-V定义
       case CAUSE_STORE_PAGE_FAULT:
           uintptr_t addr = tf->badvaddr;  // fault地址
           pte_t *ptep = get_pte(current->pgdir, addr, 0);
           if (ptep && (*ptep & PTE_V) && !(*ptep & PTE_W)) {
               struct Page *page = pte2page(*ptep);
               if (PageCOW(page)) {  // 共享页面
                   struct Page *npage = alloc_page();
                   if (!npage) return -E_NO_MEM;
                   void *src_kvaddr = page2kva(page);
                   void *dst_kvaddr = page2kva(npage);
                   memcpy(dst_kvaddr, src_kvaddr, PGSIZE);
                   uint32_t perm = (*ptep & PTE_USER) | PTE_W;  // 设为可写
                   page_insert(current->pgdir, npage, addr, perm);
                   page_ref_dec(page);  // 减少共享计数
                   npage->pra_vaddr = addr;  // 记录新页面的虚拟地址
                   return 0;  // 继续执行
               }
           }
           break;
       ```

3. **其他修改**：
   - **权限一致性**：在fork时，确保父进程页面也设为只读（修改`do_fork`或`copy_thread`中父进程的权限）。
   - **退出处理**：在`do_exit`中，正确减少ref计数，避免内存泄漏。

4. **状态转换（有限状态自动机风格）**：
   - **初始状态**：页面未共享，ref=1，可写。
   - **共享状态**：fork后，ref>1，只读（COW标记）。
   - **写触发**：page fault → 复制 → 新页面ref=1，可写；原页面ref--。
   - **释放**：进程退出时，ref--；若ref=0，释放页面。






### 练习3: 阅读分析源代码，理解进程执行 fork/exec/wait/exit 的实现，以及系统调用的实现（不需要编码）

请在实验报告中简要说明你对 fork/exec/wait/exit函数的分析。并回答如下问题：

请分析fork/exec/wait/exit的执行流程。重点关注哪些操作是在用户态完成，哪些是在内核态完成？内核态与用户态程序是如何交错执行的？内核态执行结果是如何返回给用户程序的？

请给出ucore中一个用户态进程的执行状态生命周期图（包执行状态，执行状态之间的变换关系，以及产生变换的事件或函数调用）。（字符方式画即可）

执行：make grade。如果所显示的应用程序检测都输出ok，则基本正确。（使用的是qemu-1.0.1）

### 扩展练习 Challenge

1. 实现 Copy on Write （COW）机制

给出实现源码,测试用例和设计报告（包括在cow情况下的各种状态转换（类似有限状态自动机）的说明）。

这个扩展练习涉及到本实验和上一个实验“虚拟内存管理”。在ucore操作系统中，当一个用户父进程创建自己的子进程时，父进程会把其申请的用户空间设置为只读，子进程可共享父进程占用的用户内存空间中的页面（这就是一个共享的资源）。当其中任何一个进程修改此用户内存空间中的某页面时，ucore会通过page fault异常获知该操作，并完成拷贝内存页面，使得两个进程都有各自的内存页面。这样一个进程所做的修改不会被另外一个进程可见了。请在ucore中实现这样的COW机制。

由于COW实现比较复杂，容易引入bug，请参考 https://dirtycow.ninja/ 看看能否在ucore的COW实现中模拟这个错误和解决方案。需要有解释。

这是一个big challenge.

2. 说明该用户程序是何时被预先加载到内存中的？与我们常用操作系统的加载有何区别，原因是什么？





## 列出你认为本实验中重要的知识点，以及与对应的OS原理中的知识点，并简要说明你对二者的含义，关系，差异等方面的理解（也可能出现实验中的知识点没有对应的原理知识点）






## lab2分支任务：gdb 调试页表查询过程
本实验核心目标：理解虚拟地址到物理地址的转换过程：通过双重GDB调试，观察CPU访问虚拟地址时，QEMU如何模拟硬件完成地址翻译。
在QEMU中，GDB调试功能主要通过以下关键组件和调用路径实现：

(1)GDB Stub初始化
gdbserver_start() 初始化GDB服务器
gdb_handlesig() 处理来自guest的信号
gdb_read_byte() 读取GDB命令

(2)内存访问相关调用路径
target_memory_rw_debug() 提供调试内存读写接口
cpu_memory_rw_debug() CPU特定的内存读写实现
对于物理内存模式，直接使用 cpu_physical_memory_read() / cpu_physical_memory_write()

(3)地址翻译调用路径
riscv_cpu_get_phys_page_debug() 获取虚拟地址对应的物理地址
get_physical_address() 执行实际的页表遍历和地址翻译     


在地址翻译过程中，有几个关键的分支判断：
特权级别判断：

```c
if (mode == PRV_M) {
    ...
} else {
    ...
}
```
页表项有效性检查：

```c
if (!(pte & PTE_V)) {
    /* Invalid PTE */
    return TRANSLATE_FAIL;
}
```

权限检查：
```c
if (access_type == MMU_DATA_LOAD && !((pte & PTE_R) ||
           ((pte & PTE_X) && mxr))) {
    /* Read access check failed */
    return TRANSLATE_FAIL;
}
```
下面是具体调试：
1. 编译带调试信息的qemu:
```
# 进入QEMU源码目录
cd qemu-4.1.1

# 清理之前的编译结果
make distclean

# 重新配置，这次要带上调试选项
./configure --target-list=riscv32-softmmu,riscv64-softmmu --enable-debug

# 重新编译
make -j$(nproc)
```
![alt text](image1.png)
2. 修改Makefile指向新编译的调试版QEMU
![alt text](image2.png)
3. 准备三个终端窗口进行协同调试
终端1：运行make debug启动QEMU
在项目目录下执行：
```
make debug
```
这个命令会启动我们新编译的调试版QEMU，并暂停在初始状态。

终端2：使用普通GDB附加到QEMU进程，调试QEMU源码
首先，我们需要找到QEMU进程的PID：
```
pgrep -f qemu-system-riscv64
```
得到PID：13220
然后启动GDB并附加到这个进程：
```
sudo gdb
(gdb)attach 13220
(gdb) handle SIGPIPE nostop noprint
(gdb) # 你可以在这里执行一些操作，设置一些断点等
(gdb) continue # 之后就启动执行
```
关于handle SIGPIPE nostop noprint
SIGPIPE 是一种 Unix 信号，当进程试图向一个已经被关闭的管道或套接字写入数据时会产生这个信号。在 QEMU 调试过程中，这种情况可能会频繁发生。
这个命令告诉 GDB：
* nostop - 收到 SIGPIPE 时不暂停程序执行
* noprint - 收到 SIGPIPE 时不打印相关信息
如果不处理 SIGPIPE：
（1）GDB 会中断执行
当 QEMU 进程收到 SIGPIPE 信号时，GDB 默认会暂停程序执行
你会看到类似这样的信息：Program received signal SIGPIPE, Broken pipe.

（2）调试过程被打断
每次出现 SIGPIPE 信号，GDB 都会停止并等待你的输入
你需要手动输入 continue 或 signal 13 等命令来继续执行
这会使调试过程变得非常繁琐和低效

（3）影响调试体验
SIGPIPE 信号在 QEMU 正常运行过程中可能会频繁出现
频繁的手动干预会影响你对真正关注的断点的调试

之后执行的操作：
```
(gdb) break riscv_cpu_tlb_fill
(gdb) break riscv_cpu_exec_interrupt
(gdb) break get_physical_address
```
这里设置了三个断点当QEMU执行到这些关键代码时会自动暂停，方便观察地址翻译的具体过程。

终端3：使用riscv64-unknown-elf-gdb调试运行在QEMU中的ucore内核
在gdb已经设置好断点并启动qemu的执行（即执行了continue）之后，在项目目录下执行：
```
make gdb
```
这个GDB会话会连接到QEMU的GDB stub，就像我们平时调试内核一样。可以在这里控制ucore的执行，比如打断点让它在某个访存指令处暂停、通过指令查看寄存器的值，某个符号的地址等。

4. 观察地址转换流程
 make gdb之后，可以看到gdb的内容：
```

 Thread 1 "qemu-system-ris" hit Breakpoint 4, get_physical_address (
    env=0x5df792530140, physical=0x7ffc74b23208, prot=0x7ffc74b23200, addr=0, 
    access_type=0, mmu_idx=3)
    at /home/liuyueshuai/桌面/labcode/lab1/qemu-4.1.1/target/riscv/cpu_helper.c:158
158	{
```
这里断点在get_physical_address函数中，这个函数是QEMU中用于获取物理地址的函数。
* 函数：get_physical_address
* 虚拟地址：addr=0
* 访问类型：access_type=0（读访问）
* MMU索引：mmu_idx=3
下面执行list命令查看get_physical_address函数的源码：
```
此处仅展示部分
{
    /* NOTE: the env->pc value visible here will not be
     * correct, but the value visible to the exception handler
     * (riscv_cpu_do_interrupt) is correct */

    int mode = mmu_idx;

    if (mode == PRV_M && access_type != MMU_INST_FETCH) {
        if (get_field(env->mstatus, MSTATUS_MPRV)) {
            mode = get_field(env->mstatus, MSTATUS_MPP);
        }
    }

    if (mode == PRV_M || !riscv_feature(env, RISCV_FEATURE_MMU)) {
        *physical = addr;
        *prot = PAGE_READ | PAGE_WRITE | PAGE_EXEC;
        return TRANSLATE_SUCCESS;
    }

    *prot = 0;

    target_ulong base;
    int levels, ptidxbits, ptesize, vm, sum;
    int mxr = get_field(env->mstatus, MSTATUS_MXR);

    if (env->priv_ver >= PRIV_VERSION_1_10_0) {
        base = get_field(env->satp, SATP_PPN) << PGSHIFT;
        sum = get_field(env->mstatus, MSTATUS_SUM);
        vm = get_field(env->satp, SATP_MODE);
        switch (vm) {
        case VM_1_10_SV32:
          levels = 2; ptidxbits = 10; ptesize = 4; break;
        case VM_1_10_SV39:
          levels = 3; ptidxbits = 9; ptesize = 8; break;
        case VM_1_10_SV48:
          levels = 4; ptidxbits = 9; ptesize = 8; break;
        case VM_1_10_SV57:
          levels = 5; ptidxbits = 9; ptesize = 8; break;
        case VM_1_10_MBARE:
            *physical = addr;
            *prot = PAGE_READ | PAGE_WRITE | PAGE_EXEC;
            return TRANSLATE_SUCCESS;
        default:
          g_assert_not_reached();
        }
    } else {
        base = env->sptbr << PGSHIFT;
        sum = !get_field(env->mstatus, MSTATUS_PUM);
        vm = get_field(env->mstatus, MSTATUS_VM);
        switch (vm) {
        case VM_1_09_SV32:
          levels = 2; ptidxbits = 10; ptesize = 4; break;
        case VM_1_09_SV39:
          levels = 3; ptidxbits = 9; ptesize = 8; break;
        case VM_1_09_SV48:
          levels = 4; ptidxbits = 9; ptesize = 8; break;
        case VM_1_09_MBARE:
            *physical = addr;
            *prot = PAGE_READ | PAGE_WRITE | PAGE_EXEC;
            return TRANSLATE_SUCCESS;
        default:
          g_assert_not_reached();
        }
    }

    CPUState *cs = env_cpu(env);
    int va_bits = PGSHIFT + levels * ptidxbits;
    target_ulong mask = (1L << (TARGET_LONG_BITS - (va_bits - 1))) - 1;
    target_ulong masked_msbs = (addr >> (va_bits - 1)) & mask;
    if (masked_msbs != 0 && masked_msbs != mask) {
        return TRANSLATE_FAIL;
    }

    int ptshift = (levels - 1) * ptidxbits;
    int i;
    ......
}
```
1.**地址翻译入口点**
当CPU需要访问一个虚拟地址时，QEMU会调用get_physical_address()函数来执行地址翻译。这个函数接收以下参数：

* CPURISCVState *env: CPU状态，包含寄存器和其他相关信息
* hwaddr *physical: 输出参数，用于存储翻译后的物理地址
* int *prot: 输出参数，用于存储页面的访问权限
* target_ulong addr: 需要翻译的虚拟地址
* int access_type: 访问类型（指令获取、数据加载或数据存储）
* int mmu_idx: MMU索引，表示当前特权级别

2.**确定页表基址和模式**
首先，函数会根据当前CPU的特权级别确定使用的页表：

```c
if (mode == PRV_M) {
    // 机器模式(M-mode)通常直接访问物理地址，除非显式启用分页
    // ...
} else {
    // 用户模式(U-mode)或监管模式(S-mode)使用页表
    base = env->sptbr << PGSHIFT;  // 在较老版本中使用sptbr
    // 或者在新版本中使用:
    // base = get_field(env->satp, SATP_PPN) << PGSHIFT;
    
    vm = get_field(env->mstatus, MSTATUS_VM);  // 或使用SATP中的模式位
    switch (vm) {
    case VM_1_09_SV32:
      levels = 2; ptidxbits = 10; ptesize = 4; break;
    case VM_1_09_SV39:
      levels = 3; ptidxbits = 9; ptesize = 8; break;
    case VM_1_09_SV48:
      levels = 4; ptidxbits = 9; ptesize = 8; break;
    // ...
    }
}
```
3. 逐级页表遍历
接下来，函数会逐级遍历页表：

```c
int ptshift = (levels - 1) * ptidxbits;
for (i = 0; i < levels; i++, ptshift -= ptidxbits) {
    // 计算当前级页表的索引
    target_ulong idx = (addr >> (PGSHIFT + ptshift)) & ((1 << ptidxbits) - 1);
    
    // 计算页表项的物理地址
    target_ulong pte_addr = base + idx * ptesize;
    
    // 从物理内存中读取页表项
#if defined(TARGET_RISCV32)
    target_ulong pte = ldl_phys(cs->as, pte_addr);
#elif defined(TARGET_RISCV64)
    target_ulong pte = ldq_phys(cs->as, pte_addr);
#endif
    
    // 解析页表项中的物理页号
    target_ulong ppn = pte >> PTE_PPN_SHIFT;
```
然后使用step命令进行逐行调试，查看get_physical_address函数的运行过程，重点查看TLB查询的过程，使用print env->satp可以观察到satp的值。
这个函数本身是TLB缺失时的处理函数。当硬件TLB未命中时，会调用此函数进行软件页表遍历。
在函数末尾，计算出的物理地址和权限信息会被用于更新TLB条目：
```
*physical = (ppn | (vpn & ((1L << ptshift) - 1))) << PGSHIFT;
```

